"","...1","title","author","subject","abstract","meta"
"1",1,"telemoma: a modular and versatile teleoperation system for mobile manipulation","shivin dass, wensi ai, yuqian jiang, samik singh, jiaheng hu, ruohan zhang, peter stone, ben abbatematteo, roberto martin-martin","robotics","a critical bottleneck limiting imitation learning in robotics is the lack of data. this problem is more severe in mobile manipulation, where collecting demonstrations is harder than in stationary manipulation due to the lack of available and easy-to-use teleoperation interfaces. in this work, we demonstrate telemoma, a general and modular interface for whole-body teleoperation of mobile manipulators. telemoma unifies multiple human interfaces including rgb and depth cameras, virtual reality controllers, keyboard, joysticks, etc., and any combination thereof. in its more accessible version, telemoma works using simply vision (e.g., an rgb-d camera), lowering the entry bar for humans to provide mobile manipulation demonstrations. we demonstrate the versatility of telemoma by teleoperating several existing mobile manipulators - pal tiago++, toyota hsr, and fetch - in simulation and the real world. we demonstrate the quality of the demonstrations collected with telemoma by training imitation learning policies for mobile manipulation tasks involving synchronized whole-body motion. finally, we also show that telemoma's teleoperation channel enables teleoperation on site, looking at the robot, or remote, sending commands and observations through a computer network, and perform user studies to evaluate how easy it is for novice users to learn to collect demonstrations with different combinations of human interfaces enabled by our system. we hope telemoma becomes a helpful tool for the community enabling researchers to collect whole-body mobile manipulation demonstrations. for more information and video results, this https url.",2024-03-12
"2",2,"exploring safety generalization challenges of large language models via code","qibing ren, chang gao, jing shao, junchi yan, xin tan, wai lam, lizhuang ma","computation and language","the rapid advancement of large language models (llms) has brought about remarkable capabilities in natural language processing but also raised concerns about their potential misuse. while strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods primarily focus on natural languages, which may not generalize to other domains. this paper introduces codeattack, a framework that transforms natural language inputs into code inputs, presenting a novel environment for testing the safety generalization of llms. our comprehensive studies on state-of-the-art llms including gpt-4, claude-2, and llama-2 series reveal a common safety vulnerability of these models against code input: codeattack consistently bypasses the safety guardrails of all models more than 80\% of the time. furthermore, we find that a larger distribution gap between codeattack and natural language leads to weaker safety generalization, such as encoding natural language input with data structures or using less popular programming languages. these findings highlight new safety risks in the code domain and the need for more robust safety alignment algorithms to match the code capabilities of llms.",2024-03-12
"3",3,"low coordinate degree algorithms i: universality of computational thresholds for hypothesis testing","dmitriy kunisky","statistics theory","we study when low coordinate degree functions (lcdf) -- linear combinations of functions depending on small subsets of entries of a vector -- can hypothesis test between high-dimensional probability measures. these functions are a generalization, proposed in hopkins' 2018 thesis but seldom studied since, of low degree polynomials (ldp), a class widely used in recent literature as a proxy for all efficient algorithms for tasks in statistics and optimization. instead of the orthogonal polynomial decompositions used in ldp calculations, our analysis of lcdf is based on the efron-stein or anova decomposition, making it much more broadly applicable. by way of illustration, we prove channel universality for the success of lcdf in testing for the presence of sufficiently ""dilute"" random signals through noisy channels: the efficacy of lcdf depends on the channel only through the scalar fisher information for a class of channels including nearly arbitrary additive i.i.d. noise and nearly arbitrary exponential families. as applications, we extend lower bounds against ldp for spiked matrix and tensor models under additive gaussian noise to lower bounds against lcdf under general noisy channels. we also give a simple and unified treatment of the effect of censoring models by erasing observations at random and of quantizing models by taking the sign of the observations. these results are the first computational lower bounds against any large class of algorithms for all of these models when the channel is not one of a few special cases, and thereby give the first substantial evidence for the universality of several statistical-to-computational gaps.",2024-03-12
"4",4,"fairness feedback loops: training on synthetic data amplifies bias","sierra wyllie, ilia shumailov, nicolas papernot","machine learning","model-induced distribution shifts (mids) occur as previous model outputs pollute new model training sets over generations of models. this is known as model collapse in the case of generative models, and performative prediction or unfairness feedback loops for supervised models. when a model induces a distribution shift, it also encodes its mistakes, biases, and unfairnesses into the ground truth of its data ecosystem. we introduce a framework that allows us to track multiple mids over many generations, finding that they can lead to loss in performance, fairness, and minoritized group representation, even in initially unbiased datasets. despite these negative consequences, we identify how models might be used for positive, intentional, interventions in their data ecosystems, providing redress for historical discrimination through a framework called algorithmic reparation (ar). we simulate ar interventions by curating representative training batches for stochastic gradient descent to demonstrate how ar can improve upon the unfairnesses of models and data ecosystems subject to other mids. our work takes an important step towards identifying, mitigating, and taking accountability for the unfair feedback loops enabled by the idea that ml systems are inherently neutral and objective.",2024-03-12
"5",5,"quantum support vector machine for prostate cancer detection: a performance analysis","walid el maouaki, taoufik said, mohamed bennai","machine learning","this study addresses the urgent need for improved prostate cancer detection methods by harnessing the power of advanced technological solutions. we introduce the application of quantum support vector machine (qsvm) to this critical healthcare challenge, showcasing an enhancement in diagnostic performance over the classical support vector machine (svm) approach. our study not only outlines the remarkable improvements in diagnostic performance made by qsvm over the classic svm technique, but it delves into the advancements brought about by the quantum feature map architecture, which has been carefully identified and evaluated, ensuring it aligns seamlessly with the unique characteristics of our prostate cancer dataset. this architecture succeded in creating a distinct feature space, enabling the detection of complex, non-linear patterns in the data. the findings reveal not only a comparable accuracy with classical svm ($92\%$) but also a $7.14\%$ increase in sensitivity and a notably high f1-score ($93.33\%$). this study's important combination of quantum computing in medical diagnostics marks a pivotal step forward in cancer detection, offering promising implications for the future of healthcare technology.",2024-03-12
"6",6,"distilling the knowledge in data pruning","emanuel ben-baruch, adam botach, igor kviatkovsky, manoj aggarwal, g√©rard medioni","computer vision and pattern recognition","with the increasing size of datasets used for training neural networks, data pruning becomes an attractive field of research. however, most current data pruning algorithms are limited in their ability to preserve accuracy compared to models trained on the full data, especially in high pruning regimes. in this paper we explore the application of data pruning while incorporating knowledge distillation (kd) when training on a pruned subset. that is, rather than relying solely on ground-truth labels, we also use the soft predictions from a teacher network pre-trained on the complete data. by integrating kd into training, we demonstrate significant improvement across datasets, pruning methods, and on all pruning fractions. we first establish a theoretical motivation for employing self-distillation to improve training on pruned data. then, we empirically make a compelling and highly practical observation: using kd, simple random pruning is comparable or superior to sophisticated pruning methods across all pruning regimes. on imagenet for example, we achieve superior accuracy despite training on a random subset of only 50% of the data. additionally, we demonstrate a crucial connection between the pruning factor and the optimal knowledge distillation weight. this helps mitigate the impact of samples with noisy labels and low-quality images retained by typical pruning algorithms. finally, we make an intriguing observation: when using lower pruning fractions, larger teachers lead to accuracy degradation, while surprisingly, employing teachers with a smaller capacity than the student's may improve results. our code will be made available.",2024-03-12
"7",7,"12 mj per class on-device online few-shot class-incremental learning","yoga esa wibowo, cristian cioflan, thorir mar ingolfsson, michael hersche, leo zhao, abbas rahimi, luca benini","machine learning","few-shot class-incremental learning (fscil) enables machine learning systems to expand their inference capabilities to new classes using only a few labeled examples, without forgetting the previously learned classes. classical backpropagation-based learning and its variants are often unsuitable for battery-powered, memory-constrained systems at the extreme edge. in this work, we introduce online few-shot class-incremental learning (o-fscil), based on a lightweight model consisting of a pretrained and metalearned feature extractor and an expandable explicit memory storing the class prototypes. the architecture is pretrained with a novel feature orthogonality regularization and metalearned with a multi-margin loss. for learning a new class, our approach extends the explicit memory with novel class prototypes, while the remaining architecture is kept frozen. this allows learning previously unseen classes based on only a few examples with one single pass (hence online). o-fscil obtains an average accuracy of 68.62% on the fscil cifar100 benchmark, achieving state-of-the-art results. tailored for ultra-low-power platforms, we implement o-fscil on the 60 mw gap9 microcontroller, demonstrating online learning capabilities within just 12 mj per new class.",2024-03-12
"8",8,"iterative graph neural network enhancement via frequent subgraph mining of explanations","harish g. naik, jan polster, raj shekhar, tam√°s horv√°th, gy√∂rgy tur√°n","machine learning","we formulate an xai-based model improvement approach for graph neural networks (gnns) for node classification, called explanation enhanced graph learning (eegl). the goal is to improve predictive performance of gnn using explanations. eegl is an iterative self-improving algorithm, which starts with a learned ""vanilla"" gnn, and repeatedly uses frequent subgraph mining to find relevant patterns in explanation subgraphs. these patterns are then filtered further to obtain application-dependent features corresponding to the presence of certain subgraphs in the node neighborhoods. giving an application-dependent algorithm for such a subgraph-based extension of the weisfeiler-leman (1-wl) algorithm has previously been posed as an open problem. we present experimental evidence, with synthetic and real-world data, which show that eegl outperforms related approaches in predictive performance and that it has a node-distinguishing power beyond that of vanilla gnns. we also analyze eegl's training dynamics.",2024-03-12
"9",9,"hyper-density functional theory of soft matter","florian samm√ºller, silas robitschko, sophie hermann, matthias schmidt","soft condensed matter","we present a scheme for investigating arbitrary thermal observables in spatially inhomogeneous many-body systems. extending the equilibrium ensemble yields any given observable as an explicit hyper-density functional. associated local fluctuation profiles follow from an exact hyper-ornstein-zernike equation. simulation-based supervised machine learning trains neural networks that act as hyper-direct correlation functionals which facilitate efficient and accurate predictions. we exemplify the approach for the cluster statistics of hard rods and square well particles. the theory provides access to complex order parameters, as is impossible in standard density functional theory.",2024-03-12
"10",10,"a machine learning and empirical bayesian approach for predictive buying in b2b e-commerce","tuhin subhra de, pranjal singh, alok patel","machine learning","in the context of developing nations like india, traditional business to business (b2b) commerce heavily relies on the establishment of robust relationships, trust, and credit arrangements between buyers and sellers. consequently, ecommerce enterprises frequently. established in 2016 with a vision to revolutionize trade in india through technology, udaan is the countrys largest business to business ecommerce platform. udaan operates across diverse product categories, including lifestyle, electronics, home and employ telecallers to cultivate buyer relationships, streamline order placement procedures, and promote special promotions. the accurate anticipation of buyer order placement behavior emerges as a pivotal factor for attaining sustainable growth, heightening competitiveness, and optimizing the efficiency of these telecallers. to address this challenge, we have employed an ensemble approach comprising xgboost and a modified version of poisson gamma model to predict customer order patterns with precision. this paper provides an in-depth exploration of the strategic fusion of machine learning and an empirical bayesian approach, bolstered by the judicious selection of pertinent features. this innovative approach has yielded a remarkable 3 times increase in customer order rates, show casing its potential for transformative impact in the ecommerce industry.",2024-03-12
"11",11,"quantifying and mitigating privacy risks for tabular generative models","chaoyi zhu, jiayi tang, hans brouwer, juan f. p√©rez, marten van dijk, lydia y. chen","machine learning","synthetic data from generative models emerges as the privacy-preserving data-sharing solution. such a synthetic data set shall resemble the original data without revealing identifiable private information. the backbone technology of tabular synthesizers is rooted in image generative models, ranging from generative adversarial networks (gans) to recent diffusion models. recent prior work sheds light on the utility-privacy tradeoff on tabular data, revealing and quantifying privacy risks on synthetic data. we first conduct an exhaustive empirical analysis, highlighting the utility-privacy tradeoff of five state-of-the-art tabular synthesizers, against eight privacy attacks, with a special focus on membership inference attacks. motivated by the observation of high data quality but also high privacy risk in tabular diffusion, we propose dp-tldm, differentially private tabular latent diffusion model, which is composed of an autoencoder network to encode the tabular data and a latent diffusion model to synthesize the latent tables. following the emerging f-dp framework, we apply dp-sgd to train the auto-encoder in combination with batch clipping and use the separation value as the privacy metric to better capture the privacy gain from dp algorithms. our empirical evaluation demonstrates that dp-tldm is capable of achieving a meaningful theoretical privacy guarantee while also significantly enhancing the utility of synthetic data. specifically, compared to other dp-protected tabular generative models, dp-tldm improves the synthetic quality by an average of 35% in data resemblance, 15% in the utility for downstream tasks, and 50% in data discriminability, all while preserving a comparable level of privacy risk.",2024-03-12
"12",12,"mpcpa: multi-center privacy computing with predictions aggregation based on denoising diffusion probabilistic model","guibo luo, hanwen zhang, xiuling wang, mingzhi chen, yuesheng zhu","distributed, parallel, and cluster computing","privacy-preserving computing is crucial for multi-center machine learning in many applications such as healthcare and finance. in this paper a multi-center privacy computing framework with predictions aggregation (mpcpa) based on denoising diffusion probabilistic model (ddpm) is proposed, in which conditional diffusion model training, ddpm data generation, a classifier, and strategy of prediction aggregation are included. compared to federated learning, this framework necessitates fewer communications and leverages high-quality generated data to support robust privacy computing. experimental validation across multiple datasets demonstrates that the proposed framework outperforms classic federated learning and approaches the performance of centralized learning with original data. moreover, our approach demonstrates robust security, effectively addressing challenges such as image memorization and membership inference attacks. our experiments underscore the efficacy of the proposed framework in the realm of privacy computing, with the code set to be released soon.",2024-03-12
"13",13,"when eye-tracking meets machine learning: a systematic review on applications in medical image analysis","sahar moradizeyveh, mehnaz tabassum, sidong liu, robert ahadizad newport, amin beheshti, antonio di ieva","image and video processing","eye-gaze tracking research offers significant promise in enhancing various healthcare-related tasks, above all in medical image analysis and interpretation. eye tracking, a technology that monitors and records the movement of the eyes, provides valuable insights into human visual attention patterns. this technology can transform how healthcare professionals and medical specialists engage with and analyze diagnostic images, offering a more insightful and efficient approach to medical diagnostics. hence, extracting meaningful features and insights from medical images by leveraging eye-gaze data improves our understanding of how radiologists and other medical experts monitor, interpret, and understand images for diagnostic purposes. eye-tracking data, with intricate human visual attention patterns embedded, provides a bridge to integrating artificial intelligence (ai) development and human cognition. this integration allows novel methods to incorporate domain knowledge into machine learning (ml) and deep learning (dl) approaches to enhance their alignment with human-like perception and decision-making. moreover, extensive collections of eye-tracking data have also enabled novel ml/dl methods to analyze human visual patterns, paving the way to a better understanding of human vision, attention, and cognition. this systematic review investigates eye-gaze tracking applications and methodologies for enhancing ml/dl algorithms for medical image analysis in depth.",2024-03-12
"14",14,"fusing climate data products using a spatially varying autoencoder","jacob a. johnson, matthew j. heaton, william f. christensen, lynsie r. warr, summer b. rupper","applications","autoencoders are powerful machine learning models used to compress information from multiple data sources. however, autoencoders, like all artificial neural networks, are often unidentifiable and uninterpretable. this research focuses on creating an identifiable and interpretable autoencoder that can be used to meld and combine climate data products. the proposed autoencoder utilizes a bayesian statistical framework, allowing for probabilistic interpretations while also varying spatially to capture useful spatial patterns across the various data products. constraints are placed on the autoencoder as it learns patterns in the data, creating an interpretable consensus that includes the important features from each input. we demonstrate the utility of the autoencoder by combining information from multiple precipitation products in high mountain asia.",2024-03-12
"15",15,"label dropout: improved deep learning echocardiography segmentation using multiple datasets with domain shift and partial labelling","iman islam (1), esther puyol-ant√≥n (1), bram ruijsink (1), andrew j. reader (1), andrew p. king (1) ((1) king's college london)","computer vision and pattern recognition","echocardiography (echo) is the first imaging modality used when assessing cardiac function. the measurement of functional biomarkers from echo relies upon the segmentation of cardiac structures and deep learning models have been proposed to automate the segmentation process. however, in order to translate these tools to widespread clinical use it is important that the segmentation models are robust to a wide variety of images (e.g. acquired from different scanners, by operators with different levels of expertise etc.). to achieve this level of robustness it is necessary that the models are trained with multiple diverse datasets. a significant challenge faced when training with multiple diverse datasets is the variation in label presence, i.e. the combined data are often partially-labelled. adaptations of the cross entropy loss function have been proposed to deal with partially labelled data. in this paper we show that training naively with such a loss function and multiple diverse datasets can lead to a form of shortcut learning, where the model associates label presence with domain characteristics, leading to a drop in performance. to address this problem, we propose a novel label dropout scheme to break the link between domain characteristics and the presence or absence of labels. we demonstrate that label dropout improves echo segmentation dice score by 62% and 25% on two cardiac structures when training using multiple diverse partially labelled datasets.",2024-03-12
"16",16,"chronos: learning the language of time series","abdul fatir ansari, lorenzo stella, caner turkmen, xiyuan zhang, pedro mercado, huibin shen, oleksandr shchur, syama sundar rangapuram, sebastian pineda arango, shubham kapoor, jasper zschiegner, danielle c. maddix, michael w. mahoney, kari torkkola, andrew gordon wilson, michael bohlke-schneider, yuyang wang","machine learning","we introduce chronos, a simple yet effective framework for pretrained probabilistic time series models. chronos tokenizes time series values using scaling and quantization into a fixed vocabulary and trains existing transformer-based language model architectures on these tokenized time series via the cross-entropy loss. we pretrained chronos models based on the t5 family (ranging from 20m to 710m parameters) on a large collection of publicly available datasets, complemented by a synthetic dataset that we generated via gaussian processes to improve generalization. in a comprehensive benchmark consisting of 42 datasets, and comprising both classical local models and deep learning methods, we show that chronos models: (a) significantly outperform other methods on datasets that were part of the training corpus; and (b) have comparable and occasionally superior zero-shot performance on new datasets, relative to methods that were trained specifically on them. our results demonstrate that chronos models can leverage time series data from diverse domains to improve zero-shot accuracy on unseen forecasting tasks, positioning pretrained models as a viable tool to greatly simplify forecasting pipelines.",2024-03-12
"17",17,"pyvene: a library for understanding and improving pytorch models via interventions","zhengxuan wu, atticus geiger, aryaman arora, jing huang, zheng wang, noah d. goodman, christopher d. manning, christopher potts","machine learning","interventions on model-internal states are fundamental operations in many areas of ai, including model editing, steering, robustness, and interpretability. to facilitate such research, we introduce $\textbf{pyvene}$, an open-source python library that supports customizable interventions on a range of different pytorch modules. $\textbf{pyvene}$ supports complex intervention schemes with an intuitive configuration format, and its interventions can be static or include trainable parameters. we show how $\textbf{pyvene}$ provides a unified and extensible framework for performing interventions on neural models and sharing the intervened upon models with others. we illustrate the power of the library via interpretability analyses using causal abstraction and knowledge localization. we publish our library through python package index (pypi) and provide code, documentation, and tutorials at this https url.",2024-03-12
"18",18,"boosting keyword spotting through on-device learnable user speech characteristics","cristian cioflan, lukas cavigelli, luca benini","sound","keyword spotting systems for always-on tinyml-constrained applications require on-site tuning to boost the accuracy of offline trained classifiers when deployed in unseen inference conditions. adapting to the speech peculiarities of target users requires many in-domain samples, often unavailable in real-world scenarios. furthermore, current on-device learning techniques rely on computationally intensive and memory-hungry backbone update schemes, unfit for always-on, battery-powered devices. in this work, we propose a novel on-device learning architecture, composed of a pretrained backbone and a user-aware embedding learning the user's speech characteristics. the so-generated features are fused and used to classify the input utterance. for domain shifts generated by unseen speakers, we measure error rate reductions of up to 19% from 30.1% to 24.3% based on the 35-class problem of the google speech commands dataset, through the inexpensive update of the user projections. we moreover demonstrate the few-shot learning capabilities of our proposed architecture in sample- and class-scarce learning conditions. with 23.7 kparameters and 1 mflop per epoch required for on-device training, our system is feasible for tinyml applications aimed at battery-powered microcontrollers.",2024-03-12
"19",19,"joint selection: adaptively incorporating public information for private synthetic data","miguel fuentes, brett mullins, ryan mckenna, gerome miklau, daniel sheldon","machine learning","mechanisms for generating differentially private synthetic data based on marginals and graphical models have been successful in a wide range of settings. however, one limitation of these methods is their inability to incorporate public data. initializing a data generating model by pre-training on public data has shown to improve the quality of synthetic data, but this technique is not applicable when model structure is not determined a priori. we develop the mechanism jam-pgm, which expands the adaptive measurements framework to jointly select between measuring public data and private data. this technique allows for public data to be included in a graphical-model-based mechanism. we show that jam-pgm is able to outperform both publicly assisted and non publicly assisted synthetic data generation mechanisms even when the public data distribution is biased.",2024-03-12
"20",20,"fine-tuning neural network quantum states","riccardo rende, sebastian goldt, federico becca, luciano loris viteritti","disordered systems and neural networks","recent progress in the design and optimization of neural network quantum states (nnqs) have made them an effective method to investigate ground-state properties of quantum many-body systems. in contrast to the standard approach of training a separate nnqs from scratch at every point of the phase diagram, we demonstrate that the optimization at a highly expressive point of the phase diagram (i.e., close to a phase transition) yields interpretable features that can be reused to accurately describe a wide region across the transition. we demonstrate the feasibility of our approach on different systems in one and two dimensions by initially pretraining a nnqs at a given point of the phase diagram, followed by fine-tuning only the output layer for all other points. notably, the computational cost of the fine-tuning step is very low compared to the pretraining stage. we argue that the reduced cost of this paradigm has significant potential to advance the exploration of condensed matter systems using nnqs, mirroring the success of fine-tuning in machine learning and natural language processing.",2024-03-12
"21",21,"dexcap: scalable and portable mocap data collection system for dexterous manipulation","chen wang, haochen shi, weizhuo wang, ruohan zhang, li fei-fei, c. karen liu","robotics","imitation learning from human hand motion data presents a promising avenue for imbuing robots with human-like dexterity in real-world manipulation tasks. despite this potential, substantial challenges persist, particularly with the portability of existing hand motion capture (mocap) systems and the difficulty of translating mocap data into effective control policies. to tackle these issues, we introduce dexcap, a portable hand motion capture system, alongside dexil, a novel imitation algorithm for training dexterous robot skills directly from human hand mocap data. dexcap offers precise, occlusion-resistant tracking of wrist and finger motions based on slam and electromagnetic field together with 3d observations of the environment. utilizing this rich dataset, dexil employs inverse kinematics and point cloud-based imitation learning to replicate human actions with robot hands. beyond learning from human motion, dexcap also offers an optional human-in-the-loop correction mechanism to refine and further improve robot performance. through extensive evaluation across six dexterous manipulation tasks, our approach not only demonstrates superior performance but also showcases the system's capability to effectively learn from in-the-wild mocap data, paving the way for future data collection methods for dexterous manipulation. more details can be found at this https url",2024-03-12
"22",22,"fairrr: pre-processing for group fairness through randomized response","xianli zeng, joshua ward, guang cheng","machine learning","the increasing usage of machine learning models in consequential decision-making processes has spurred research into the fairness of these systems. while significant work has been done to study group fairness in the in-processing and post-processing setting, there has been little that theoretically connects these results to the pre-processing domain. this paper proposes that achieving group fairness in downstream models can be formulated as finding the optimal design matrix in which to modify a response variable in a randomized response framework. we show that measures of group fairness can be directly controlled for with optimal model utility, proposing a pre-processing algorithm called fairrr that yields excellent downstream model utility and fairness.",2024-03-12
"23",23,"beyond the labels: unveiling text-dependency in paralinguistic speech recognition datasets","jan pe≈°√°n, santosh kesiraju, luk√°≈° burget, jan ''honza'' ƒçernock√Ω","audio and speech processing","paralinguistic traits like cognitive load and emotion are increasingly recognized as pivotal areas in speech recognition research, often examined through specialized datasets like clse and iemocap. however, the integrity of these datasets is seldom scrutinized for text-dependency. this paper critically evaluates the prevalent assumption that machine learning models trained on such datasets genuinely learn to identify paralinguistic traits, rather than merely capturing lexical features. by examining the lexical overlap in these datasets and testing the performance of machine learning models, we expose significant text-dependency in trait-labeling. our results suggest that some machine learning models, especially large pre-trained models like hubert, might inadvertently focus on lexical characteristics rather than the intended paralinguistic features. the study serves as a call to action for the research community to reevaluate the reliability of existing datasets and methodologies, ensuring that machine learning models genuinely learn what they are designed to recognize.",2024-03-12
"24",24,"emerging technologies for 6g non-terrestrial-networks: from academia to industrial applications","cong t. nguyen, yuris mulya saputra, nguyen van huynh, tan n. nguyen, dinh thai hoang, diep n nguyen, van-quan pham, miroslav voznak, symeon chatzinotas, dinh-hieu tran","networking and internet architecture","terrestrial networks form the fundamental infrastructure of modern communication systems, serving more than 4 billion users globally. however, terrestrial networks are facing a wide range of challenges, from coverage and reliability to interference and congestion. as the demands of the 6g era are expected to be much higher, it is crucial to address these challenges to ensure a robust and efficient communication infrastructure for the future. to address these problems, non-terrestrial network (ntn) has emerged to be a promising solution. ntns are communication networks that leverage airborne (e.g., unmanned aerial vehicles) and spaceborne vehicles (e.g., satellites) to facilitate ultra-reliable communications and connectivity with high data rates and low latency over expansive regions. this article aims to provide a comprehensive survey on the utilization of network slicing, artificial intelligence/machine learning (ai/ml), and open radio access network (oran) to address diverse challenges of ntns from the perspectives of both academia and industry. particularly, we first provide an in-depth tutorial on ntn and the key enabling technologies including network slicing, ai/ml, and oran. then, we provide a comprehensive survey on how network slicing and ai/ml have been leveraged to overcome the challenges that ntns are facing. moreover, we present how oran can be utilized for ntns. finally, we highlight important challenges, open issues, and future research directions of ntn in the 6g era.",2024-03-12
"25",25,"supporting annotators with affordances for efficiently labeling conversational data","austin z. henley, david piorkowski","human-computer interaction","without well-labeled ground truth data, machine learning-based systems would not be as ubiquitous as they are today, but these systems rely on substantial amounts of correctly labeled data. unfortunately, crowdsourced labeling is time consuming and expensive. to address the concerns of effort and tedium, we designed cal, a novel interface to aid in data labeling. we made several key design decisions for cal, which include preventing inapt labels from being selected, guiding users in selecting an appropriate label when they need assistance, incorporating labeling documentation into the interface, and providing an efficient means to view previous labels. we implemented a production-quality implementation of cal and report a user-study evaluation that compares cal to a standard spreadsheet. key findings of our study include users using cal reported lower cognitive load, did not increase task time, users rated cal to be easier to use, and users preferred cal over the spreadsheet.",2024-03-12
"26",26,"probabilistic easy variational causal effect","usef faghihi, amir saki","machine learning","let $x$ and $z$ be random vectors, and $y=g(x,z)$. in this paper, on the one hand, for the case that $x$ and $z$ are continuous, by using the ideas from the total variation and the flux of $g$, we develop a point of view in causal inference capable of dealing with a broad domain of causal problems. indeed, we focus on a function, called probabilistic easy variational causal effect (peace), which can measure the direct causal effect of $x$ on $y$ with respect to continuously and interventionally changing the values of $x$ while keeping the value of $z$ constant. peace is a function of $d\ge 0$, which is a degree managing the strengths of probability density values $f(x|z)$. on the other hand, we generalize the above idea for the discrete case and show its compatibility with the continuous case. further, we investigate some properties of peace using measure theoretical concepts. furthermore, we provide some identifiability criteria and several examples showing the generic capability of peace. we note that peace can deal with the causal problems for which micro-level or just macro-level changes in the value of the input variables are important. finally, peace is stable under small changes in $\partial g_{in}/\partial x$ and the joint distribution of $x$ and $z$, where $g_{in}$ is obtained from $g$ by removing all functional relationships defining $x$ and $z$.",2024-03-12
"27",27,"equipping computational pathology systems with artifact processing pipelines: a showcase for computation and performance trade-offs","neel kanwal, farbod khoraminia, umay kiraz, andres mosquera-zamudio, carlos monteagudo, emiel a.m. janssen, tahlita c.m. zuiverloon, chunmig rong, kjersti engan","image and video processing","histopathology is a gold standard for cancer diagnosis under a microscopic examination. however, histological tissue processing procedures result in artifacts, which are ultimately transferred to the digitized version of glass slides, known as whole slide images (wsis). artifacts are diagnostically irrelevant areas and may result in wrong deep learning (dl) algorithms predictions. therefore, detecting and excluding artifacts in the computational pathology (cpath) system is essential for reliable automated diagnosis. in this paper, we propose a mixture of experts (moe) scheme for detecting five notable artifacts, including damaged tissue, blur, folded tissue, air bubbles, and histologically irrelevant blood from wsis. first, we train independent binary dl models as experts to capture particular artifact morphology. then, we ensemble their predictions using a fusion mechanism. we apply probabilistic thresholding over the final probability distribution to improve the sensitivity of the moe. we developed dl pipelines using two moes and two multiclass models of state-of-the-art deep convolutional neural networks (dcnns) and vision transformers (vits). dcnns-based moe and vits-based moe schemes outperformed simpler multiclass models and were tested on datasets from different hospitals and cancer types, where moe using dcnns yielded the best results. the proposed moe yields 86.15% f1 and 97.93% sensitivity scores on unseen data, retaining less computational cost for inference than moe using vits. this best performance of moes comes with relatively higher computational trade-offs than multiclass models. the proposed artifact detection pipeline will not only ensure reliable cpath predictions but may also provide quality control.",2024-03-12
"28",28,"the minimax rate of hsic estimation for translation-invariant kernels","florian kalinke, zoltan szabo","statistics theory","kernel techniques are among the most influential approaches in data science and statistics. under mild conditions, the reproducing kernel hilbert space associated to a kernel is capable of encoding the independence of $m\ge 2$ random variables. probably the most widespread independence measure relying on kernels is the so-called hilbert-schmidt independence criterion (hsic; also referred to as distance covariance in the statistics literature). despite various existing hsic estimators designed since its introduction close to two decades ago, the fundamental question of the rate at which hsic can be estimated is still open. in this work, we prove that the minimax optimal rate of hsic estimation on $\mathbb r^d$ for borel measures containing the gaussians with continuous bounded translation-invariant characteristic kernels is $\mathcal o\!\left(n^{-1/2}\right)$. specifically, our result implies the optimality in the minimax sense of many of the most-frequently used estimators (including the u-statistic, the v-statistic, and the nystr√∂m-based one) on $\mathbb r^d$.",2024-03-12
"29",29,"dseg-lime - improving image explanation by hierarchical data-driven segmentation","patrick knab, sascha marton, christian bartelt","computer vision and pattern recognition","explainable artificial intelligence is critical in unraveling decision-making processes in complex machine learning models. lime (local interpretable model-agnostic explanations) is a well-known xai framework for image analysis. it utilizes image segmentation to create features to identify relevant areas for classification. consequently, poor segmentation can compromise the consistency of the explanation and undermine the importance of the segments, affecting the overall interpretability. addressing these challenges, we introduce dseg-lime (data-driven segmentation lime), featuring: i) a data-driven segmentation for human-recognized feature generation, and ii) a hierarchical segmentation procedure through composition. we benchmark dseg-lime on pre-trained models with images from the imagenet dataset - scenarios without domain-specific knowledge. the analysis includes a quantitative evaluation using established xai metrics, complemented by a qualitative assessment through a user study. our findings demonstrate that dseg outperforms in most of the xai metrics and enhances the alignment of explanations with human-recognized concepts, significantly improving interpretability. the code is available under: https://github. com/patrick-knab/dseg-lime",2024-03-12
"30",30,"cas: a general algorithm for online selective conformal prediction with fcr control","yajie bao, yuyang huo, haojie ren, changliang zou","machine learning","we study the problem of post-selection predictive inference in an online fashion. to avoid devoting resources to unimportant units, a preliminary selection of the current individual before reporting its prediction interval is common and meaningful in online predictive tasks. since the online selection causes a temporal multiplicity in the selected prediction intervals, it is important to control the real-time false coverage-statement rate (fcr) to measure the averaged miscoverage error. we develop a general framework named cas (calibration after adaptive selection) that can wrap around any prediction model and online selection rule to output post-selection prediction intervals. if the current individual is selected, we first perform an adaptive selection on historical data to construct a calibration set, then output a conformal prediction interval for the unobserved label. we provide tractable constructions for the calibration set for popular online selection rules. we proved that cas can achieve an exact selection-conditional coverage guarantee in the finite-sample and distribution-free regimes. for the decision-driven selection rule, including most online multiple-testing procedures, cas can exactly control the real-time fcr below the target level without any distributional assumptions. for the online selection with symmetric thresholds, we establish the error bound for the control gap of fcr under mild distributional assumptions. to account for the distribution shift in online data, we also embed cas into some recent dynamic conformal prediction methods and examine the long-run fcr control. numerical results on both synthetic and real data corroborate that cas can effectively control fcr around the target level and yield more narrowed prediction intervals over existing baselines across various settings.",2024-03-12
"31",31,"balancing fairness and accuracy in data-restricted binary classification","zachary mcbride lazri, danial dervovic, antigoni polychroniadou, ivan brugere, dana dachman-soled, min wu","machine learning","applications that deal with sensitive information may have restrictions placed on the data available to a machine learning (ml) classifier. for example, in some applications, a classifier may not have direct access to sensitive attributes, affecting its ability to produce accurate and fair decisions. this paper proposes a framework that models the trade-off between accuracy and fairness under four practical scenarios that dictate the type of data available for analysis. prior works examine this trade-off by analyzing the outputs of a scoring function that has been trained to implicitly learn the underlying distribution of the feature vector, class label, and sensitive attribute of a dataset. in contrast, our framework directly analyzes the behavior of the optimal bayesian classifier on this underlying distribution by constructing a discrete approximation it from the dataset itself. this approach enables us to formulate multiple convex optimization problems, which allow us to answer the question: how is the accuracy of a bayesian classifier affected in different data restricting scenarios when constrained to be fair? analysis is performed on a set of fairness definitions that include group and individual fairness. experiments on three datasets demonstrate the utility of the proposed framework as a tool for quantifying the trade-offs among different fairness notions and their distributional dependencies.",2024-03-12
"32",32,"on the last-iterate convergence of shuffling gradient methods","zijian liu, zhengyuan zhou","machine learning","shuffling gradient methods, which are also known as stochastic gradient descent (sgd) without replacement, are widely implemented in practice, particularly including three popular algorithms: random reshuffle (rr), shuffle once (so), and incremental gradient (ig). compared to the empirical success, the theoretical guarantee of shuffling gradient methods was not well-understanding for a long time. until recently, the convergence rates had just been established for the average iterate for convex functions and the last iterate for strongly convex problems (using squared distance as the metric). however, when using the function value gap as the convergence criterion, existing theories cannot interpret the good performance of the last iterate in different settings (e.g., constrained optimization). to bridge this gap between practice and theory, we prove last-iterate convergence rates for shuffling gradient methods with respect to the objective value even without strong convexity. our new results either (nearly) match the existing last-iterate lower bounds or are as fast as the previous best upper bounds for the average iterate.",2024-03-12
"33",33,"visual decoding and reconstruction via eeg embeddings with guided diffusion","dongyang li, chen wei, shiying li, jiachen zou, quanying liu","human-computer interaction","how to decode human vision through neural signals has attracted a long-standing interest in neuroscience and machine learning. modern contrastive learning and generative models improved the performance of fmri-based visual decoding and reconstruction. however, the high cost and low temporal resolution of fmri limit their applications in brain-computer interfaces (bcis), prompting a high need for eeg-based visual reconstruction. in this study, we present an eeg-based visual reconstruction framework. it consists of a plug-and-play eeg encoder called the adaptive thinking mapper (atm), which is aligned with image embeddings, and a two-stage eeg guidance image generator that first transforms eeg features into image priors and then reconstructs the visual stimuli with a pre-trained image generator. our approach allows eeg embeddings to achieve superior performance in image classification and retrieval tasks. our two-stage image generation strategy vividly reconstructs images seen by humans. furthermore, we analyzed the impact of signals from different time windows and brain regions on decoding and reconstruction. the versatility of our framework is demonstrated in the magnetoencephalogram (meg) data modality. we report that eeg-based visual decoding achieves sota performance, highlighting the portability, low cost, and high temporal resolution of eeg, enabling a wide range of bci applications. the code of atm is available at https://anonymous.4open.science/status/eeg_image_decode-deef.",2024-03-12
"34",34,"workarena: how capable are web agents at solving common knowledge work tasks?","alexandre drouin, maxime gasse, massimo caccia, issam h. laradji, manuel del verme, tom marty, l√©o boisvert, megh thakkar, quentin cappart, david vazquez, nicolas chapados, alexandre lacoste","machine learning","we study the use of large language model-based agents for interacting with software via web browsers. unlike prior work, we focus on measuring the agents' ability to perform tasks that span the typical daily work of knowledge workers utilizing enterprise software systems. to this end, we propose workarena, a remote-hosted benchmark of 29 tasks based on the widely-used servicenow platform. we also introduce browsergym, an environment for the design and evaluation of such agents, offering a rich set of actions as well as multimodal observations. our empirical evaluation reveals that while current agents show promise on workarena, there remains a considerable gap towards achieving full task automation. notably, our analysis uncovers a significant performance disparity between open and closed-source llms, highlighting a critical area for future exploration and development in the field.",2024-03-12
"35",35,"fast and simple explainability for point cloud networks","meir yossef levi, guy gilboa","computer vision and pattern recognition","we propose a fast and simple explainable ai (xai) method for point cloud data. it computes pointwise importance with respect to a trained network downstream task. this allows better understanding of the network properties, which is imperative for safety-critical applications. in addition to debugging and visualization, our low computational complexity facilitates online feedback to the network at inference. this can be used to reduce uncertainty and to increase robustness. in this work, we introduce \emph{feature based interpretability} (fbi), where we compute the features' norm, per point, before the bottleneck. we analyze the use of gradients and post- and pre-bottleneck strategies, showing pre-bottleneck is preferred, in terms of smoothness and ranking. we obtain at least three orders of magnitude speedup, compared to current xai methods, thus, scalable for big point clouds or large-scale architectures. our approach achieves sota results, in terms of classification explainability. we demonstrate how the proposed measure is helpful in analyzing and characterizing various aspects of 3d learning, such as rotation invariance, robustness to out-of-distribution (ood) outliers or domain shift and dataset bias.",2024-03-12
"36",36,"symmetric q-learning: reducing skewness of bellman error in online reinforcement learning","motoki omura, takayuki osa, yusuke mukuta, tatsuya harada","machine learning","in deep reinforcement learning, estimating the value function to evaluate the quality of states and actions is essential. the value function is often trained using the least squares method, which implicitly assumes a gaussian error distribution. however, a recent study suggested that the error distribution for training the value function is often skewed because of the properties of the bellman operator, and violates the implicit assumption of normal error distribution in the least squares method. to address this, we proposed a method called symmetric q-learning, in which the synthetic noise generated from a zero-mean distribution is added to the target values to generate a gaussian error distribution. we evaluated the proposed method on continuous control benchmark tasks in mujoco. it improved the sample efficiency of a state-of-the-art reinforcement learning method by reducing the skewness of the error distribution.",2024-03-12
"37",37,"satdaug -- a balanced and augmented dataset for detecting self-admitted technical debt","edi sutoyo, andrea capiluppi","software engineering","self-admitted technical debt (satd) refers to a form of technical debt in which developers explicitly acknowledge and document the existence of technical shortcuts, workarounds, or temporary solutions within the codebase. over recent years, researchers have manually labeled datasets derived from various software development artifacts: source code comments, messages from the issue tracker and pull request sections, and commit messages. these datasets are designed for training, evaluation, performance validation, and improvement of machine learning and deep learning models to accurately identify satd instances. however, class imbalance poses a serious challenge across all the existing datasets, particularly when researchers are interested in categorizing the specific types of satd. in order to address the scarcity of labeled data for satd \textit{identification} (i.e., whether an instance is satd or not) and \textit{categorization} (i.e., which type of satd is being classified) in existing datasets, we share the \textit{satdaug} dataset, an augmented version of existing satd datasets, including source code comments, issue tracker, pull requests, and commit messages. these augmented datasets have been balanced in relation to the available artifacts and provide a much richer source of labeled data for training machine learning or deep learning models.",2024-03-12
"38",38,"maxwell's demon at work: efficient pruning by leveraging saturation of neurons","simon dufort-labb√©, pierluca d'oro, evgenii nikishin, razvan pascanu, pierre-luc bacon, aristide baratin","machine learning","when training deep neural networks, the phenomenon of $\textit{dying neurons}$ $\unicode{x2013}$units that become inactive or saturated, output zero during training$\unicode{x2013}$ has traditionally been viewed as undesirable, linked with optimization challenges, and contributing to plasticity loss in continual learning scenarios. in this paper, we reassess this phenomenon, focusing on sparsity and pruning. by systematically exploring the impact of various hyperparameter configurations on dying neurons, we unveil their potential to facilitate simple yet effective structured pruning algorithms. we introduce $\textit{demon pruning}$ (demp), a method that controls the proliferation of dead neurons, dynamically leading to network sparsity. achieved through a combination of noise injection on active units and a one-cycled schedule regularization strategy, demp stands out for its simplicity and broad applicability. experiments on cifar10 and imagenet datasets demonstrate that demp surpasses existing structured pruning techniques, showcasing superior accuracy-sparsity tradeoffs and training speedups. these findings suggest a novel perspective on dying neurons as a valuable resource for efficient model compression and optimization.",2024-03-12
"39",39,"moralbert: detecting moral values in social discourse","vjosa preniqi, iacopo ghinassi, kyriaki kalimeri, charalampos saitis","computation and language","morality plays a fundamental role in how we perceive information while greatly influencing our decisions and judgements. controversial topics, including vaccination, abortion, racism, and sexuality, often elicit opinions and attitudes that are not solely based on evidence but rather reflect moral worldviews. recent advances in natural language processing have demonstrated that moral values can be gauged in human-generated textual content. here, we design a range of language representation models fine-tuned to capture exactly the moral nuances in text, called moralbert. we leverage annotated moral data from three distinct sources: twitter, reddit, and facebook user-generated content covering various socially relevant topics. this approach broadens linguistic diversity and potentially enhances the models' ability to comprehend morality in various contexts. we also explore a domain adaptation technique and compare it to the standard fine-tuned bert model, using two different frameworks for moral prediction: single-label and multi-label. we compare in-domain approaches with conventional models relying on lexicon-based techniques, as well as a machine learning classifier with word2vec representation. our results showed that in-domain prediction models significantly outperformed traditional models. while the single-label setting reaches a higher accuracy than previously achieved for the task when using bert pretrained models. experiments in an out-of-domain setting, instead, suggest that further work is needed for existing domain adaptation techniques to generalise between different social media platforms, especially for the multi-label task. the investigations and outcomes from this study pave the way for further exploration, enabling a more profound comprehension of moral narratives about controversial social issues.",2024-03-12
"40",40,"machine learning for soccer match result prediction","rory bunker, calvin yeung, keisuke fujii","machine learning","machine learning has become a common approach to predicting the outcomes of soccer matches, and the body of literature in this domain has grown substantially in the past decade and a half. this chapter discusses available datasets, the types of models and features, and ways of evaluating model performance in this application domain. the aim of this chapter is to give a broad overview of the current state and potential future developments in machine learning for soccer match results prediction, as a resource for those interested in conducting future studies in the area. our main findings are that while gradient-boosted tree models such as catboost, applied to soccer-specific ratings such as pi-ratings, are currently the best-performing models on datasets containing only goals as the match features, there needs to be a more thorough comparison of the performance of deep learning models and random forest on a range of datasets with different types of features. furthermore, new rating systems using both player- and team-level information and incorporating additional information from, e.g., spatiotemporal tracking and event data, could be investigated further. finally, the interpretability of match result prediction models needs to be enhanced for them to be more useful for team management.",2024-03-12
"41",41,"optical computing with supercontinuum generation in photonic crystal fibers","azka maula iskandar muda, uƒüur teƒüin","optics","we introduce a novel photonic neural network using photonic crystal fibers, leveraging femtosecond pulse supercontinuum generation for optical computing. investigating its efficacy across machine learning tasks, we uncover the crucial impact of nonlinear pulse propagation dynamics on network performance. our findings show that octave-spanning supercontinuum generation results in loss of dataset variety due to many-to-one mapping, and optimal performance requires balancing optical nonlinearity. this study offers guidance for designing energy-efficient and high-performance photonic neural network architectures by explaining the interplay between nonlinear dynamics and optical computing.",2024-03-12
"42",42,"scalable spatiotemporal prediction with bayesian neural fields","feras saad, jacob burnim, colin carroll, brian patton, urs k√∂ster, rif a. saurous, matthew hoffman","machine learning","spatiotemporal datasets, which consist of spatially-referenced time series, are ubiquitous in many scientific and business-intelligence applications, such as air pollution monitoring, disease tracking, and cloud-demand forecasting. as modern datasets continue to increase in size and complexity, there is a growing need for new statistical methods that are flexible enough to capture complex spatiotemporal dynamics and scalable enough to handle large prediction problems. this work presents the bayesian neural field (bayesnf), a domain-general statistical model for inferring rich probability distributions over a spatiotemporal domain, which can be used for data-analysis tasks including forecasting, interpolation, and variography. bayesnf integrates a novel deep neural network architecture for high-capacity function estimation with hierarchical bayesian inference for robust uncertainty quantification. by defining the prior through a sequence of smooth differentiable transforms, posterior inference is conducted on large-scale data using variationally learned surrogates trained via stochastic gradient descent. we evaluate bayesnf against prominent statistical and machine-learning baselines, showing considerable improvements on diverse prediction problems from climate and public health datasets that contain tens to hundreds of thousands of measurements. the paper is accompanied with an open-source software package (this https url) that is easy-to-use and compatible with modern gpu and tpu accelerators on the jax machine learning platform.",2024-03-12
"43",43,"harder tasks need more experts: dynamic routing in moe models","quzhe huang, zhenwei an, nan zhuang, mingxu tao, chen zhang, yang jin, kun xu, kun xu, liwei chen, songfang huang, yansong feng","machine learning","in this paper, we introduce a novel dynamic expert selection framework for mixture of experts (moe) models, aiming to enhance computational efficiency and model performance by adjusting the number of activated experts based on input difficulty. unlike traditional moe approaches that rely on fixed top-k routing, which activates a predetermined number of experts regardless of the input's complexity, our method dynamically selects experts based on the confidence level in expert selection for each input. this allows for a more efficient utilization of computational resources, activating more experts for complex tasks requiring advanced reasoning and fewer for simpler tasks. through extensive evaluations, our dynamic routing method demonstrates substantial improvements over conventional top-2 routing across various benchmarks, achieving an average improvement of 0.7% with less than 90% activated parameters. further analysis shows our model dispatches more experts to tasks requiring complex reasoning skills, like bbh, confirming its ability to dynamically allocate computational resources in alignment with the input's complexity. our findings also highlight a variation in the number of experts needed across different layers of the transformer model, offering insights into the potential for designing heterogeneous moe frameworks. the code and models are available at this https url.",2024-03-12
"44",44,"characterization of large language model development in the datacenter","qinghao hu, zhisheng ye, zerui wang, guoteng wang, meng zhang, qiaoling chen, peng sun, dahua lin, xiaolin wang, yingwei luo, yonggang wen, tianwei zhang","distributed, parallel, and cluster computing","large language models (llms) have presented impressive performance across several transformative tasks. however, it is non-trivial to efficiently utilize large-scale cluster resources to develop llms, often riddled with numerous challenges such as frequent hardware failures, intricate parallelization strategies, and imbalanced resource utilization. in this paper, we present an in-depth characterization study of a six-month llm development workload trace collected from our gpu datacenter acme. specifically, we investigate discrepancies between llms and prior task-specific deep learning (dl) workloads, explore resource utilization patterns, and identify the impact of various job failures. our analysis summarizes hurdles we encountered and uncovers potential opportunities to optimize systems tailored for llms. furthermore, we introduce our system efforts: (1) fault-tolerant pretraining, which enhances fault tolerance through llm-involved failure diagnosis and automatic recovery. (2) decoupled scheduling for evaluation, which achieves timely performance feedback via trial decomposition and scheduling optimization.",2024-03-12
"45",45,"cardiogenai: a machine learning-based framework for re-engineering drugs for reduced herg liability","gregory w. kyro, matthew t. martin, eric d. watt, victor s. batista","machine learning","drug-induced cardiotoxicity is a major health concern which can lead to serious adverse effects including life-threatening cardiac arrhythmias via the blockade of the voltage-gated herg potassium ion channel. it is therefore of tremendous interest to develop advanced methods to identify herg-active compounds in early stages of drug development, as well as to optimize commercially available drugs for reduced herg activity. in this work, we present cardiogenai, a machine learning-based framework for re-engineering both developmental and marketed drugs for reduced herg activity while preserving their pharmacological activity. the framework incorporates novel state-of-the-art discriminative models for predicting herg channel activity, as well as activity against the voltage-gated nav1.5 and cav1.2 channels due to their potential implications in modulating the arrhythmogenic potential induced by herg channel blockade. these models can also serve independently as effective components of a virtual screening pipeline. we applied the complete framework to pimozide, an fda-approved antipsychotic agent that demonstrates high affinity to the herg channel, and generated 100 refined candidates. remarkably, among the candidates is fluspirilene, a compound which is of the same class of drugs (diphenylmethanes) as pimozide and therefore has similar pharmacological activity, yet exhibits over 700-fold weaker binding to herg. we have made all of our software open-source to facilitate integration of the cardiogenai framework for molecular hypothesis generation into drug discovery workflows.",2024-03-12
"46",46,"generaitor: tree-in-the-loop text generation for language model explainability and adaptation","thilo spinner, rebecca kehlbeck, rita sevastjanova, tobias st√§hle, daniel a. keim, oliver deussen, mennatallah el-assady","human-computer interaction","large language models (llms) are widely deployed in various downstream tasks, e.g., auto-completion, aided writing, or chat-based text generation. however, the considered output candidates of the underlying search algorithm are under-explored and under-explained. we tackle this shortcoming by proposing a tree-in-the-loop approach, where a visual representation of the beam search tree is the central component for analyzing, explaining, and adapting the generated outputs. to support these tasks, we present generaitor, a visual analytics technique, augmenting the central beam search tree with various task-specific widgets, providing targeted visualizations and interaction possibilities. our approach allows interactions on multiple levels and offers an iterative pipeline that encompasses generating, exploring, and comparing output candidates, as well as fine-tuning the model based on adapted data. our case study shows that our tool generates new insights in gender bias analysis beyond state-of-the-art template-based methods. additionally, we demonstrate the applicability of our approach in a qualitative user study. finally, we quantitatively evaluate the adaptability of the model to few samples, as occurring in text-generation use cases.",2024-03-12
"47",47,"efficient knowledge deletion from trained models through layer-wise partial machine unlearning","vinay chakravarthi gogineni, esmaeil s. nadimi","machine learning","machine unlearning has garnered significant attention due to its ability to selectively erase knowledge obtained from specific training data samples in an already trained machine learning model. this capability enables data holders to adhere strictly to data protection regulations. however, existing unlearning techniques face practical constraints, often causing performance degradation, demanding brief fine-tuning post unlearning, and requiring significant storage. in response, this paper introduces a novel class of machine unlearning algorithms. first method is partial amnesiac unlearning, integration of layer-wise pruning with amnesiac unlearning. in this method, updates made to the model during training are pruned and stored, subsequently used to forget specific data from trained model. the second method assimilates layer-wise partial-updates into label-flipping and optimization-based unlearning to mitigate the adverse effects of data deletion on model efficacy. through a detailed experimental evaluation, we showcase the effectiveness of proposed unlearning methods. experimental results highlight that the partial amnesiac unlearning not only preserves model efficacy but also eliminates the necessity for brief post fine-tuning, unlike conventional amnesiac unlearning. moreover, employing layer-wise partial updates in label-flipping and optimization-based unlearning techniques demonstrates superiority in preserving model efficacy compared to their naive counterparts.",2024-03-12
"48",48,"couler: unified machine learning workflow optimization in cloud","xiaoda wang, yuan tang, tengda guo, bo sang, jingji wu, jian sha, ke zhang, jiang qian, mingjie tang","databases","machine learning (ml) has become ubiquitous, fueling data-driven applications across various organizations. contrary to the traditional perception of ml in research, ml workflows can be complex, resource-intensive, and time-consuming. expanding an ml workflow to encompass a wider range of data infrastructure and data types may lead to larger workloads and increased deployment costs. currently, numerous workflow engines are available (with over ten being widely recognized). this variety poses a challenge for end-users in terms of mastering different engine apis. while efforts have primarily focused on optimizing ml operations (mlops) for a specific workflow engine, current methods largely overlook workflow optimization across different engines. in this work, we design and implement couler, a system designed for unified ml workflow optimization in the cloud. our main insight lies in the ability to generate an ml workflow using natural language (nl) descriptions. we integrate large language models (llms) into workflow generation, and provide a unified programming interface for various workflow engines. this approach alleviates the need to understand various workflow engines' apis. moreover, couler enhances workflow computation efficiency by introducing automated caching at multiple stages, enabling large workflow auto-parallelization and automatic hyperparameters tuning. these enhancements minimize redundant computational costs and improve fault tolerance during deep learning workflow training. couler is extensively deployed in real-world production scenarios at ant group, handling approximately 22k workflows daily, and has successfully improved the cpu/memory utilization by more than 15% and the workflow completion rate by around 17%.",2024-03-12
"49",49,"optimizing negative prompts for enhanced aesthetics and fidelity in text-to-image generation","michael ogezi, ning shi","computer vision and pattern recognition","in text-to-image generation, using negative prompts, which describe undesirable image characteristics, can significantly boost image quality. however, producing good negative prompts is manual and tedious. to address this, we propose negopt, a novel method for optimizing negative prompt generation toward enhanced image generation, using supervised fine-tuning and reinforcement learning. our combined approach results in a substantial increase of 25% in inception score compared to other approaches and surpasses ground-truth negative prompts from the test set. furthermore, with negopt we can preferentially optimize the metrics most important to us. finally, we construct negative prompts db, a dataset of negative prompts.",2024-03-12
"50",50,"propml: probability partial multi-label learning","≈Çukasz struski, adam pardyl, jacek tabor, bartosz zieli≈Ñski","machine learning","partial multi-label learning (pml) is a type of weakly supervised learning where each training instance corresponds to a set of candidate labels, among which only some are true. in this paper, we introduce \our{}, a novel probabilistic approach to this problem that extends the binary cross entropy to the pml setup. in contrast to existing methods, it does not require suboptimal disambiguation and, as such, can be applied to any deep architecture. furthermore, experiments conducted on artificial and real-world datasets indicate that \our{} outperforms existing approaches, especially for high noise in a candidate set.",2024-03-12
"51",51,"robustifying and boosting training-free neural architecture search","zhenfeng he, yao shu, zhongxiang dai, bryan kian hsiang low","machine learning","neural architecture search (nas) has become a key component of automl and a standard tool to automate the design of deep neural networks. recently, training-free nas as an emerging paradigm has successfully reduced the search costs of standard training-based nas by estimating the true architecture performance with only training-free metrics. nevertheless, the estimation ability of these metrics typically varies across different tasks, making it challenging to achieve robust and consistently good search performance on diverse tasks with only a single training-free metric. meanwhile, the estimation gap between training-free metrics and the true architecture performances limits training-free nas to achieve superior performance. to address these challenges, we propose the robustifying and boosting training-free nas (robot) algorithm which (a) employs the optimized combination of existing training-free metrics explored from bayesian optimization to develop a robust and consistently better-performing metric on diverse tasks, and (b) applies greedy search, i.e., the exploitation, on the newly developed metric to bridge the aforementioned gap and consequently to boost the search performance of standard training-free nas further. remarkably, the expected performance of our robot can be theoretically guaranteed, which improves over the existing training-free nas under mild conditions with additional interesting insights. our extensive experiments on various nas benchmark tasks yield substantial empirical evidence to support our theoretical results.",2024-03-12
"52",52,"visual privacy auditing with diffusion models","kristian schwethelm, johannes kaiser, moritz knolle, daniel rueckert, georgios kaissis, alexander ziller","machine learning","image reconstruction attacks on machine learning models pose a significant risk to privacy by potentially leaking sensitive information. although defending against such attacks using differential privacy (dp) has proven effective, determining appropriate dp parameters remains challenging. current formal guarantees on data reconstruction success suffer from overly theoretical assumptions regarding adversary knowledge about the target data, particularly in the image domain. in this work, we empirically investigate this discrepancy and find that the practicality of these assumptions strongly depends on the domain shift between the data prior and the reconstruction target. we propose a reconstruction attack based on diffusion models (dms) that assumes adversary access to real-world image priors and assess its implications on privacy leakage under dp-sgd. we show that (1) real-world data priors significantly influence reconstruction success, (2) current reconstruction bounds do not model the risk posed by data priors well, and (3) dms can serve as effective auditing tools for visualizing privacy leakage.",2024-03-12
"53",53,"federated learning of socially appropriate agent behaviours in simulated home environments","saksham checker, nikhil churamani, hatice gunes","machine learning","as social robots become increasingly integrated into daily life, ensuring their behaviours align with social norms is crucial. for their widespread open-world application, it is important to explore federated learning (fl) settings where individual robots can learn about their unique environments while also learning from each others' experiences. in this paper, we present a novel fl benchmark that evaluates different strategies, using multi-label regression objectives, where each client individually learns to predict the social appropriateness of different robot actions while also sharing their learning with others. furthermore, splitting the training data by different contexts such that each client incrementally learns across contexts, we present a novel federated continual learning (fcl) benchmark that adapts fl-based methods to use state-of-the-art continual learning (cl) methods to continually learn socially appropriate agent behaviours under different contextual settings. federated averaging (fedavg) of weights emerges as a robust fl strategy while rehearsal-based fcl enables incrementally learning the social appropriateness of robot actions, across contextual splits.",2024-03-12
"54",54,"communication optimization for distributed training: architecture, advances, and opportunities","yunze wei, tianshuo hu, cong liang, yong cui","distributed, parallel, and cluster computing","the past few years have witnessed the flourishing of large-scale deep neural network models with ever-growing parameter numbers. training such large-scale models typically requires massive memory and computing resources that exceed those of a single gpu, necessitating distributed training. as gpu performance has rapidly evolved in recent years, computation time has shrunk, thereby increasing the proportion of communication in the overall training time. therefore, optimizing communication for distributed training has become an urgent issue. in this article, we briefly introduce the general architecture of distributed deep neural network training and analyze relationships among parallelization strategy, collective communication library, and network from the perspective of communication optimization, which forms a three-layer paradigm. we then review current representative research advances with this three-layer paradigm. we find that layers in the current three-layer paradigm are relatively independent, but there is a rich design space for cross-layer collaborative optimization in distributed training scenarios. therefore, we further advocate a communication-efficient five-layer paradigm underlining opportunities for collaboration designs and look forward to the perspectives of ""vertical"", ""horizontal"", ""intra-inter"" and ""host-net"" collaboration designs. we hope this article can shed some light on future research on communication optimization for distributed training.",2024-03-12
"55",55,"molecularity: a fast and efficient criterion for probing superconductivity","mat√≠as e. di mauro, beno√Æt bra√Øda, ion errea, trinidad novoa, julia contreras-garc√≠a","superconductivity","we present an efficient criterion for probing the critical temperature of hydrogen based superconductors. we start by expanding the applicability of 3d descriptors of electron localization to superconducting states within the framework of superconducting dft. we first apply this descriptor to a model system, the hydrogen chain, which allows to prove two main concepts: i) that the electron localization changes very little when the transition from the normal to the superconducting state takes place, i.e. that it can be described at the dft level from the normal state; and ii) that the formation of molecules can be characterized within this theoretical framework, enabling to filter out systems with marked molecular character and hence with low potential to be good superconductors. these two ideas, are then exploited in real binary and ternary systems, showing i) that the bonding type can be characterized automatically; and ii) that this provides a new index which enables to feed machine learning algorithms for a better prediction of critical temperatures. overall, this sets a grounded theoretical scenario for an automatic and efficient high-throughput of potential hydrogen based superconductors.",2024-03-12
"56",56,"towards a dynamic future with adaptable computing and network convergence (acnc)","masoud shokrnezhad, hao yu, tarik taleb, richard li, kyunghan lee, jaeseung song, cedric westphal","networking and internet architecture","in the context of advancing 6g, a substantial paradigm shift is anticipated, highlighting comprehensive everything-to-everything interactions characterized by numerous connections and stringent adherence to quality of service/experience (qos/e) prerequisites. the imminent challenge stems from resource scarcity, prompting a deliberate transition to computing-network convergence (cnc) as an auspicious approach for joint resource orchestration. while cnc-based mechanisms have garnered attention, their effectiveness in realizing future services, particularly in use cases like the metaverse, may encounter limitations due to the continually changing nature of users, services, and resources. hence, this paper presents the concept of adaptable cnc (acnc) as an autonomous machine learning (ml)-aided mechanism crafted for the joint orchestration of computing and network resources, catering to dynamic and voluminous user requests with stringent requirements. acnc encompasses two primary functionalities: state recognition and context detection. given the intricate nature of the user-service-computing-network space, the paper employs dimension reduction to generate live, holistic, abstract system states in a hierarchical structure. to address the challenges posed by dynamic changes, continual learning (cl) is employed, classifying the system state into contexts controlled by dedicated ml agents, enabling them to operate efficiently. these two functionalities are intricately linked within a closed loop overseen by the end-to-end (e2e) orchestrator to allocate resources. the paper introduces the components of acnc, proposes a metaverse scenario to exemplify acnc's role in resource provisioning with segment routing v6 (srv6), outlines acnc's workflow, details a numerical analysis for efficiency assessment, and concludes with discussions on relevant challenges and potential avenues for future research.",2024-03-12
"57",57,"exploring challenges in deep learning of single-station ground motion records","√ºmit mert √ßaƒülar, baris yilmaz, melek t√ºrkmen, erdem akag√ºnd√ºz, salih tileylioglu","signal processing","contemporary deep learning models have demonstrated promising results across various applications within seismology and earthquake engineering. these models rely primarily on utilizing ground motion records for tasks such as earthquake event classification, localization, earthquake early warning systems, and structural health monitoring. however, the extent to which these models effectively learn from these complex time-series signals has not been thoroughly analyzed. in this study, our objective is to evaluate the degree to which auxiliary information, such as seismic phase arrival times or seismic station distribution within a network, dominates the process of deep learning from ground motion records, potentially hindering its effectiveness. we perform a hyperparameter search on two deep learning models to assess their effectiveness in deep learning from ground motion records while also examining the impact of auxiliary information on model performance. experimental results reveal a strong reliance on the highly correlated p and s phase arrival information. our observations highlight a potential gap in the field, indicating an absence of robust methodologies for deep learning of single-station ground motion recordings independent of any auxiliary information.",2024-03-12
"58",58,"triples-to-isixhosa (t2x): addressing the challenges of low-resource agglutinative data-to-text generation","francois meyer, jan buys","computation and language","most data-to-text datasets are for english, so the difficulties of modelling data-to-text for low-resource languages are largely unexplored. in this paper we tackle data-to-text for isixhosa, which is low-resource and agglutinative. we introduce triples-to-isixhosa (t2x), a new dataset based on a subset of webnlg, which presents a new linguistic context that shifts modelling demands to subword-driven techniques. we also develop an evaluation framework for t2x that measures how accurately generated text describes the data. this enables future users of t2x to go beyond surface-level metrics in evaluation. on the modelling side we explore two classes of methods - dedicated data-to-text models trained from scratch and pretrained language models (plms). we propose a new dedicated architecture aimed at agglutinative data-to-text, the subword segmental pointer generator (sspg). it jointly learns to segment words and copy entities, and outperforms existing dedicated models for 2 agglutinative languages (isixhosa and finnish). we investigate pretrained solutions for t2x, which reveals that standard plms come up short. fine-tuning machine translation models emerges as the best method overall. these findings underscore the distinct challenge presented by t2x: neither well-established data-to-text architectures nor customary pretrained methodologies prove optimal. we conclude with a qualitative analysis of generation errors and an ablation study.",2024-03-12
"59",59,"learning generalizable feature fields for mobile manipulation","ri-zhao qiu, yafei hu, ge yang, yuchen song, yang fu, jianglong ye, jiteng mu, ruihan yang, nikolay atanasov, sebastian scherer, xiaolong wang","robotics","an open problem in mobile manipulation is how to represent objects and scenes in a unified manner, so that robots can use it both for navigating in the environment and manipulating objects. the latter requires capturing intricate geometry while understanding fine-grained semantics, whereas the former involves capturing the complexity inherit to an expansive physical scale. in this work, we present geff (generalizable feature fields), a scene-level generalizable neural feature field that acts as a unified representation for both navigation and manipulation that performs in real-time. to do so, we treat generative novel view synthesis as a pre-training task, and then align the resulting rich scene priors with natural language via clip feature distillation. we demonstrate the effectiveness of this approach by deploying geff on a quadrupedal robot equipped with a manipulator. we evaluate geff's ability to generalize to open-set objects as well as running time, when performing open-vocabulary mobile manipulation in dynamic scenes.",2024-03-12
"60",60,"a flexible cell classification for ml projects in jupyter notebooks","miguel perez, selin aydin, horst lichter","software engineering","jupyter notebook is an interactive development environment commonly used for rapid experimentation of machine learning (ml) solutions. describing the ml activities performed along code cells improves the readability and understanding of notebooks. manual annotation of code cells is time-consuming and error-prone. therefore, tools have been developed that classify the cells of a notebook concerning the ml activity performed in them. however, the current tools are not flexible, as they work based on look-up tables that have been created, which map function calls of commonly used ml libraries to ml activities. these tables must be manually adjusted to account for new or changed libraries. this paper presents a more flexible approach to cell classification based on a hybrid classification approach that combines a rule-based and a decision tree classifier. we discuss the design rationales and describe the developed classifiers in detail. we implemented the new flexible cell classification approach in a tool called jupylabel. its evaluation and the obtained metric scores regarding precision, recall, and f1-score are discussed. additionally, we compared jupylabel with headergen, an existing cell classification tool. we were able to show that the presented flexible cell classification approach outperforms this tool significantly.",2024-03-12
"61",61,"ensembling prioritized hybrid policies for multi-agent pathfinding","huijie tang, federico berto, jinkyoo park","multiagent systems","multi-agent reinforcement learning (marl) based multi-agent path finding (mapf) has recently gained attention due to its efficiency and scalability. several marl-mapf methods choose to use communication to enrich the information one agent can perceive. however, existing works still struggle in structured environments with high obstacle density and a high number of agents. to further improve the performance of the communication-based marl-mapf solvers, we propose a new method, ensembling prioritized hybrid policies (eph). we first propose a selective communication block to gather richer information for better agent coordination within multi-agent environments and train the model with a q-learning-based algorithm. we further introduce three advanced inference strategies aimed at bolstering performance during the execution phase. first, we hybridize the neural policy with single-agent expert guidance for navigating conflict-free zones. secondly, we propose q value-based methods for prioritized resolution of conflicts as well as deadlock situations. finally, we introduce a robust ensemble method that can efficiently collect the best out of multiple possible solutions. we empirically evaluate eph in complex multi-agent environments and demonstrate competitive performance against state-of-the-art neural methods for mapf.",2024-03-12
"62",62,"sifid: reassess summary factual inconsistency detection with llm","jiuding yang, hui liu, weidong guo, zhuwei rao, yu xu, di niu","computation and language","ensuring factual consistency between the summary and the original document is paramount in summarization tasks. consequently, considerable effort has been dedicated to detecting inconsistencies. with the advent of large language models (llms), recent studies have begun to leverage their advanced language understanding capabilities for inconsistency detection. however, early attempts have shown that llms underperform traditional models due to their limited ability to follow instructions and the absence of an effective detection methodology. in this study, we reassess summary inconsistency detection with llms, comparing the performances of gpt-3.5 and gpt-4. to advance research in llm-based inconsistency detection, we propose sifid (summary inconsistency detection with filtered document) that identify key sentences within documents by either employing natural language inference or measuring semantic similarity between summaries and documents.",2024-03-12
"63",63,"online continual learning for interactive instruction following agents","byeonghwi kim, minhyuk seo, jonghyun choi","artificial intelligence","in learning an embodied agent executing daily tasks via language directives, the literature largely assumes that the agent learns all training data at the beginning. we argue that such a learning scenario is less realistic since a robotic agent is supposed to learn the world continuously as it explores and perceives it. to take a step towards a more realistic embodied agent learning scenario, we propose two continual learning setups for embodied agents; learning new behaviors (behavior incremental learning, behavior-il) and new environments (environment incremental learning, environment-il) for the tasks, previous 'data prior' based continual learning methods maintain logits for the past tasks. however, the stored information is often insufficiently learned information and requires task boundary information, which might not always be available. here, we propose to update them based on confidence scores without task boundary information during training (i.e., task-free) in a moving average fashion, named confidence-aware moving average (cama). in the proposed behavior-il and environment-il setups, our simple cama outperforms prior state of the art in our empirical validations by noticeable margins. the project page including codes is this https url.",2024-03-12
"64",64,"a survey of vision transformers in autonomous driving: current trends and future directions","quoc-vinh lai-dang","computer vision and pattern recognition","this survey explores the adaptation of visual transformer models in autonomous driving, a transition inspired by their success in natural language processing. surpassing traditional recurrent neural networks in tasks like sequential image processing and outperforming convolutional neural networks in global context capture, as evidenced in complex scene recognition, transformers are gaining traction in computer vision. these capabilities are crucial in autonomous driving for real-time, dynamic visual scene processing. our survey provides a comprehensive overview of vision transformer applications in autonomous driving, focusing on foundational concepts such as self-attention, multi-head attention, and encoder-decoder architecture. we cover applications in object detection, segmentation, pedestrian detection, lane detection, and more, comparing their architectural merits and limitations. the survey concludes with future research directions, highlighting the growing role of vision transformers in autonomous driving.",2024-03-12
"65",65,"wannalaugh: a configurable ransomware emulator -- learning to mimic malicious storage traces","dionysios diamantopolous, roman pletka, slavisa sarafijanovic, a.l. narasimha reddy, haris pozidis","cryptography and security","ransomware, a fearsome and rapidly evolving cybersecurity threat, continues to inflict severe consequences on individuals and organizations worldwide. traditional detection methods, reliant on static signatures and application behavioral patterns, are challenged by the dynamic nature of these threats. this paper introduces three primary contributions to address this challenge. first, we introduce a ransomware emulator. this tool is designed to safely mimic ransomware attacks without causing actual harm or spreading malware, making it a unique solution for studying ransomware behavior. second, we demonstrate how we use this emulator to create storage i/o traces. these traces are then utilized to train machine-learning models. our results show that these models are effective in detecting ransomware, highlighting the practical application of our emulator in developing responsible cybersecurity tools. third, we show how our emulator can be used to mimic the i/o behavior of existing ransomware thereby enabling safe trace collection. both the emulator and its application represent significant steps forward in ransomware detection in the era of machine-learning-driven cybersecurity.",2024-03-12
"66",66,"lab-gatr: geometric algebra transformers for large biomedical surface and volume meshes","julian suk, baris imre, jelmer m. wolterink","computer vision and pattern recognition","many anatomical structures can be described by surface or volume meshes. machine learning is a promising tool to extract information from these 3d models. however, high-fidelity meshes often contain hundreds of thousands of vertices, which creates unique challenges in building deep neural network architectures. furthermore, patient-specific meshes may not be canonically aligned which limits the generalisation of machine learning algorithms. we propose lab-gatr, a transfomer neural network with geometric tokenisation that can effectively learn with large-scale (bio-)medical surface and volume meshes through sequence compression and interpolation. our method extends the recently proposed geometric algebra transformer (gatr) and thus respects all euclidean symmetries, i.e. rotation, translation and reflection, effectively mitigating the problem of canonical alignment between patients. lab-gatr achieves state-of-the-art results on three tasks in cardiovascular hemodynamics modelling and neurodevelopmental phenotype prediction, featuring meshes of up to 200,000 vertices. our results demonstrate that lab-gatr is a powerful architecture for learning with high-fidelity meshes which has the potential to enable interesting downstream applications. our implementation is publicly available.",2024-03-12
"67",67,"physics-transfer learning for material strength screening","yingjie zhao, zian zhang, zhiping xu","materials science","the strength of materials, like many problems in the natural sciences, spans multiple length and time scales, and the solution has to balance accuracy and performance. peierls stress is one of the central concepts in crystal plasticity that measures the strength through the resistance of a dislocation to plastic flow. the determination of peierls stress involves a multiscale nature depending on both elastic lattice responses and the energy landscape of crystal slips. material screening by strength via the peierls stress from first-principles calculations is computationally intractable for the nonlocal characteristics of dislocations, and not included in the state-of-the-art computational material databases. in this work, we propose a physics-transfer framework to learn the physics of crystal plasticity from empirical atomistic simulations and then predict the peierls stress from chemically accurate density functional theory-based calculations of material parameters. notably, the strengths of single-crystalline metals can be predicted from a few single-point calculations for the deformed lattice and on the {\gamma} surface, allowing efficient, high-throughput screening for material discovery. uncertainty quantification is carried out to assess the accuracy of models and sources of errors, showing reduced physical and system uncertainties in the predictions by elevating the fidelity of training models. this physics-transfer framework can be generalized to other problems facing the accuracy-performance dilemma, by harnessing the hierarchy of physics in the multiscale models of materials science.",2024-03-12
"68",68,"universal chemical formula dependence of $ab$ $initio$ low-energy effective hamiltonian in single-layer carrier doped cuprate superconductors -- study by hierarchical dependence extraction algorithm","jean-baptiste mor√©e, ryotaro arita","superconductivity","we explore the possibility to control the superconducting (sc) transition temperature at optimal hole doping $t_{c}^{\rm opt}$ in cuprates by tuning the chemical formula (cf). $t_{c}^{\rm opt}$ can be theoretically predicted from the parameters of the \textit{ab initio} low-energy effective hamiltonian (leh) with one antibonding (ab) cu$3d_{x^2-y^2}$/o$2p_{\sigma}$ orbital per cu atom in the cuo$_2$ plane, notably the nearest neighbor hopping amplitude $|t_1|$ and the ratio $u=u/|t_1|$, where $u$ is the onsite effective coulomb repulsion. however, the cf dependence of $|t_1|$ and $u$ is a highly nontrivial question. in this paper, we propose the universal dependence of $|t_1|$ and $u$ on the cf and structural features in hole doped cuprates with a single cuo$_2$ layer sandwiched between block layers. to do so, we perform extensive \textit{ab initio} calculations of $|t_1|$ and $u$ and analyze the results by employing a machine learning method called hierarchical dependence extraction (hde). the main results are the following: (a) $|t_1|$ has a main-order dependence on the radii $r_{\rm x}$ and $r_{\rm a}$ of the apical anion x and cation a in the block layer. ($|t_1|$ increases when $r_{\rm x}$ or $r_{\rm a}$ decreases.) (b) $u$ has a main-order dependence on the negative ionic charge $z_{\rm x}$ of x and the hole doping $\delta$ of the ab orbital. ($u$ decreases when $|z_{\rm x}|$ increases or $\delta$ increases.) we elucidate and discuss the microscopic mechanism of (a,b). we demonstrate the predictive power of the hde by showing the consistency between (a,b) and results from previous works. the present results provide a basis for optimizing sc properties in cuprates and possibly akin materials. also, the hde method offers a general platform to identify dependencies between physical quantities.",2024-03-12
"69",69,"online misogyny against female candidates in the 2022 brazilian elections: a threat to women's political representation?","luise kocha, raji ghawi, j√ºrgen pfeffer, janina isabel steinert","social and information networks","technology-facilitated gender-based violence has become a global threat to women's political representation and democracy. understanding how online hate affects its targets is thus paramount. we analyse 10 million tweets directed at female candidates in the brazilian election in 2022 and examine their reactions to online misogyny. using a self-trained machine learning classifier to detect portuguese misogynistic tweets and a quantitative analysis of the candidates' tweeting behaviour, we investigate how the number of misogynistic attacks received alters the online activity of the female candidates. we find that young and left-wing candidates and candidates with higher visibility online received significantly more attacks. furthermore, we find that an increase in misogynistic attacks in the previous week is associated with a decrease in female candidates' tweets in the following week. this potentially threatens their equal participation in public opinion building and silences women's voices in political discourse.",2024-03-12
"70",70,"reconstructions of jupiter's magnetic field using physics informed neural networks","philip w. livermore, leyuan wu, longwei chen, sjoerd a.l. de ridder","earth and planetary astrophysics","magnetic sounding using data collected from the juno mission can be used to provide constraints on jupiter's interior. however, inwards continuation of reconstructions assuming zero electrical conductivity and a representation in spherical harmonics are limited by the enhancement of noise at small scales. in this paper we describe new reconstructions of jupiter's internal magnetic field based on physics-informed neural networks and either the first 33 (pinn33) or the first 50 (pinn50) of juno's orbits. the method can resolve local structures, and allows for weak ambient electrical currents. compared with other methods, our reconstructions of jupiter's magnetic field both on and above the surface are similar, and we achieve a similar fit to the juno data. however, our models are not hampered by noise at depth, and so offer a much clearer picture of the interior structure. we estimate that the dynamo boundary is at a fractional radius of 0.8. at this depth, the magnetic field is arranged into longitudinal bands, and the great blue spot appears to be rooted in neighbouring structures of oppositely signed flux.",2024-03-12
"71",71,"constrained optimal fuel consumption of hev: a constrained reinforcement learning approach","shuchang yan","machine learning","hybrid electric vehicles (hevs) are becoming increasingly popular because they can better combine the working characteristics of internal combustion engines and electric motors. however, the minimum fuel consumption of an hev for a battery electrical balance case under a specific assembly condition and a specific speed curve still needs to be clarified in academia and industry. regarding this problem, this work provides the mathematical expression of constrained optimal fuel consumption (cofc) from the perspective of constrained reinforcement learning (crl) for the first time globally. also, two mainstream approaches of crl, constrained variational policy optimization (cvpo) and lagrangian-based approaches, are utilized for the first time to obtain the vehicle's minimum fuel consumption under the battery electrical balance condition. we conduct case studies on the well-known prius toyota hybrid system (ths) under the nedc condition; we give vital steps to implement crl approaches and compare the performance between the cvpo and lagrangian-based approaches. our case study found that cvpo and lagrangian-based approaches can obtain the lowest fuel consumption while maintaining the soc balance constraint. the cvpo approach converges stable, but the lagrangian-based approach can obtain the lowest fuel consumption at 3.95 l/100km, though with more significant oscillations. this result verifies the effectiveness of our proposed crl approaches to the cofc problem.",2024-03-12
"72",72,"detecting security-relevant methods using multi-label machine learning","oshando johnson, goran piskachev, ranjith krishnamurthy, eric bodden","machine learning","to detect security vulnerabilities, static analysis tools need to be configured with security-relevant methods. current approaches can automatically identify such methods using binary relevance machine learning approaches. however, they ignore dependencies among security-relevant methods, over-generalize and perform poorly in practice. additionally, users have to nevertheless manually configure static analysis tools using the detected methods. based on feedback from users and our observations, the excessive manual steps can often be tedious, error-prone and counter-intuitive. in this paper, we present dev-assist, an intellij idea plugin that detects security-relevant methods using a multi-label machine learning approach that considers dependencies among labels. the plugin can automatically generate configurations for static analysis tools, run the static analysis, and show the results in intellij idea. our experiments reveal that dev-assist's machine learning approach has a higher f1-measure than related approaches. moreover, the plugin reduces and simplifies the manual effort required when configuring and using static analysis tools.",2024-03-12
"73",73,"flame: fitting lyŒ± absorption lines using machine learning","priyanka jalan, vikram khaire, m. vivek, prakash gaikwad","cosmology and nongalactic astrophysics","we introduce flame, a machine learning algorithm designed to fit voigt profiles to hi lyman-alpha (ly$\alpha$) absorption lines using deep convolutional neural networks. flame integrates two algorithms: the first determines the number of components required to fit ly$\alpha$ absorption lines, and the second calculates the doppler parameter $b$, the hi column density n$_{\rm hi}$, and the velocity separation of individual components. for the current version of flame, we trained it on low-redshift ly$\alpha$ forests observed with the far ultraviolet gratings of the cosmic origin spectrograph (cos) aboard the hubble space telescope (hst). drawing on this data, we trained flame on $\sim$ $10^6$ simulated voigt profiles, forward-modeled to ly$\alpha$ absorption lines observed with hst-cos, to classify lines as either single or double components and then determine voigt profile fitting parameters. flame shows impressive accuracy on the simulated data by identifying more than 98% (90%) of single (double) component lines. it determines $b$ values within $\approx \pm{8}~(15)$ km s$^{-1}$ and log $n_{\rm hi}/ {\rm cm}^2$ values within $\approx \pm 0.3~(0.8)$ for 90% of the single (double) component lines. however, when applied to real data, flame's component classification accuracy drops by $\sim$ 10%. despite this, there is a reasonable agreement between the $b$ and n$_{\rm hi}$ distributions obtained from traditional voigt profile fitting methods and flame's predictions. our mock hst-cos data analysis, designed to emulate real data parameters, demonstrated that flame could achieve consistent accuracy comparable to its performance with simulated data. this finding suggests that the drop in flame's accuracy when used on real data primarily arises from the difficulty of replicating the full complexity of real data in the training sample.",2024-03-12
"74",74,"tuning diagonal scale matrices for hmc","jimmy huy tran, tore selland kleppe","computation","three approaches for adaptively tuning diagonal scale matrices for hmc are discussed and compared. the common practice of scaling according to estimated marginal standard deviations is taken as a benchmark. scaling according to the mean log-target gradient (isg), and a scaling method targeting that the frequency of when the underlying hamiltonian dynamics crosses the respective medians should be uniform across dimensions, are taken as alternatives. numerical studies suggest that the isg method leads in many cases to more efficient sampling than the benchmark, in particular in cases with strong correlations or non-linear dependencies. the isg method is also easy to implement, computationally cheap and would be relatively simple to include in automatically tuned codes as an alternative to the benchmark practice.",2024-03-12
"75",75,"signed graphs in data sciences via communicability geometry","fernando diaz-diaz, ernesto estrada","metric geometry","signed graphs are an emergent way of representing data in a variety of contexts were conflicting interactions exist. these include data from biological, ecological, and social systems. here we propose the concept of communicability geometry for signed graphs, proving that metrics in this space, such as the communicability distance and angles, are euclidean and spherical. we then apply these metrics to solve several problems in data analysis of signed graphs in a unified way. they include the partitioning of signed graphs, dimensionality reduction, finding hierarchies of alliances in signed networks as well as the quantification of the degree of polarization between the existing factions in systems represented by this type of graphs.",2024-03-12
"76",76,"xpertai: uncovering model strategies for sub-manifolds","simon letzgus, klaus-robert m√ºller, gr√©goire montavon","machine learning","in recent years, explainable ai (xai) methods have facilitated profound validation and knowledge extraction from ml models. while extensively studied for classification, few xai solutions have addressed the challenges specific to regression models. in regression, explanations need to be precisely formulated to address specific user queries (e.g.\ distinguishing between `why is the output above 0?' and `why is the output above 50?'). they should furthermore reflect the model's behavior on the relevant data sub-manifold. in this paper, we introduce xpertai, a framework that disentangles the prediction strategy into multiple range-specific sub-strategies and allows the formulation of precise queries about the model (the `explanandum') as a linear combination of those sub-strategies. xpertai is formulated generally to work alongside popular xai attribution techniques, based on occlusion, gradient integration, or reverse propagation. qualitative and quantitative results, demonstrate the benefits of our approach.",2024-03-12
"77",77,"pmbo: enhancing black-box optimization through multivariate polynomial surrogates","janina schreiber, pau batlle, damar wicaksono, michael hecht","optimization and control","we introduce a surrogate-based black-box optimization method, termed polynomial-model-based optimization (pmbo). the algorithm alternates polynomial approximation with bayesian optimization steps, using gaussian processes to model the error between the objective and its polynomial fit. we describe the algorithmic design of pmbo and compare the results of the performance of pmbo with several optimization methods for a set of analytic test functions. the results show that pmbo outperforms the classic bayesian optimization and is robust with respect to the choice of its correlation function family and its hyper-parameter setting, which, on the contrary, need to be carefully tuned in classic bayesian optimization. remarkably, pmbo performs comparably with state-of-the-art evolutionary algorithms such as the covariance matrix adaptation -- evolution strategy (cma-es). this finding suggests that pmbo emerges as the pivotal choice among surrogate-based optimization methods when addressing low-dimensional optimization problems. hereby, the simple nature of polynomials opens the opportunity for interpretation and analysis of the inferred surrogate model, providing a macroscopic perspective on the landscape of the objective function.",2024-03-12
"78",78,"a deep learning approach to diabetes diagnosis","zeyu zhang, khandaker asif ahmed, md rakibul hasan, tom gedeon, md zakir hossain","machine learning","diabetes, resulting from inadequate insulin production or utilization, causes extensive harm to the body. existing diagnostic methods are often invasive and come with drawbacks, such as cost constraints. although there are machine learning models like classwise k nearest neighbor (cknn) and general regression neural network (grnn), they struggle with imbalanced data and result in under-performance. leveraging advancements in sensor technology and machine learning, we propose a non-invasive diabetes diagnosis using a back propagation neural network (bpnn) with batch normalization, incorporating data re-sampling and normalization for class balancing. our method addresses existing challenges such as limited performance associated with traditional machine learning. experimental results on three datasets show significant improvements in overall accuracy, sensitivity, and specificity compared to traditional methods. notably, we achieve accuracies of 89.81% in pima diabetes dataset, 75.49% in cdc brfss2015 dataset, and 95.28% in mesra diabetes dataset. this underscores the potential of deep learning models for robust diabetes diagnosis. see project website this https url",2024-03-12
"79",79,"towards graph foundation models for personalization","andreas damianou, francesco fabbri, paul gigioli, marco de nadai, alice wang, enrico palumbo, mounia lalmas","information retrieval","in the realm of personalization, integrating diverse information sources such as consumption signals and content-based representations is becoming increasingly critical to build state-of-the-art solutions. in this regard, two of the biggest trends in research around this subject are graph neural networks (gnns) and foundation models (fms). while gnns emerged as a popular solution in industry for powering personalization at scale, fms have only recently caught attention for their promising performance in personalization tasks like ranking and retrieval. in this paper, we present a graph-based foundation modeling approach tailored to personalization. central to this approach is a heterogeneous gnn (hgnn) designed to capture multi-hop content and consumption relationships across a range of recommendable item types. to ensure the generality required from a foundation model, we employ a large language model (llm) text-based featurization of nodes that accommodates all item types, and construct the graph using co-interaction signals, which inherently transcend content specificity. to facilitate practical generalization, we further couple the hgnn with an adaptation mechanism based on a two-tower (2t) architecture, which also operates agnostically to content type. this multi-stage approach ensures high scalability; while the hgnn produces general purpose embeddings, the 2t component models in a continuous space the sheer size of user-item interaction data. our comprehensive approach has been rigorously tested and proven effective in delivering recommendations across a diverse array of products within a real-world, industrial audio streaming platform.",2024-03-12
"80",80,"imbalance-aware presence-only loss function for species distribution modeling","robin zbinden, nina van tiel, marc ru√üwurm, devis tuia","machine learning","in the face of significant biodiversity decline, species distribution models (sdms) are essential for understanding the impact of climate change on species habitats by connecting environmental conditions to species occurrences. traditionally limited by a scarcity of species observations, these models have significantly improved in performance through the integration of larger datasets provided by citizen science initiatives. however, they still suffer from the strong class imbalance between species within these datasets, often resulting in the penalization of rare species--those most critical for conservation efforts. to tackle this issue, this study assesses the effectiveness of training deep learning models using a balanced presence-only loss function on large citizen science-based datasets. we demonstrate that this imbalance-aware loss function outperforms traditional loss functions across various datasets and tasks, particularly in accurately modeling rare species with limited observations.",2024-03-12
"81",81,"on the nonconvexity of some push-forward constraints and its consequences in machine learning","lucas de lara (ut3, imt), mathis deronzier (ut3, imt), alberto gonz√°lez-sanz, virgile foy (ut3, imt)","machine learning","the push-forward operation enables one to redistribute a probability measure through a deterministic map. it plays a key role in statistics and optimization: many learning problems (notably from optimal transport, generative modeling, and algorithmic fairness) include constraints or penalties framed as push-forward conditions on the model. however, the literature lacks general theoretical insights on the (non)convexity of such constraints and its consequences on the associated learning problems. this paper aims at filling this gap. in a first part, we provide a range of sufficient and necessary conditions for the (non)convexity of two sets of functions: the maps transporting one probability measure to another; the maps inducing equal output distributions across distinct probability measures. this highlights that for most probability measures, these push-forward constraints are not convex. in a second time, we show how this result implies critical limitations on the design of convex optimization problems for learning generative models or group-fair predictors. this work will hopefully help researchers and practitioners have a better understanding of the critical impact of push-forward conditions onto convexity.",2024-03-12
"82",82,"one for all and all for one: gnn-based control-flow attestation for embedded devices","marco chilese, richard mitev, meni orenbach, robert thorburn, ahmad atamli, ahmad-reza sadeghi","cryptography and security","control-flow attestation (cfa) is a security service that allows an entity (verifier) to verify the integrity of code execution on a remote computer system (prover). existing cfa schemes suffer from impractical assumptions, such as requiring access to the prover's internal state (e.g., memory or code), the complete control-flow graph (cfg) of the prover's software, large sets of measurements, or tailor-made hardware. moreover, current cfa schemes are inadequate for attesting embedded systems due to their high computational overhead and resource usage. in this paper, we overcome the limitations of existing cfa schemes for embedded devices by introducing rage, a novel, lightweight cfa approach with minimal requirements. rage can detect code reuse attacks (cra), including control- and non-control-data attacks. it efficiently extracts features from one execution trace and leverages unsupervised graph neural networks (gnns) to identify deviations from benign executions. the core intuition behind rage is to exploit the correspondence between execution trace, execution graph, and execution embeddings to eliminate the unrealistic requirement of having access to a complete cfg. we evaluate rage on embedded benchmarks and demonstrate that (i) it detects 40 real-world attacks on embedded software; (ii) further, we stress our scheme with synthetic return-oriented programming (rop) and data-oriented programming (dop) attacks on the real-world embedded software benchmark embench, achieving 98.03% (rop) and 91.01% (dop) f1-score while maintaining a low false positive rate of 3.19%; (iii) additionally, we evaluate rage on openssl, used by millions of devices and achieve 97.49% and 84.42% f1-score for rop and dop attack detection, with an fpr of 5.47%.",2024-03-12
"83",83,"on ranking-based tests of independence","myrto limnios (ucph), st√©phan cl√©men√ßon (ltci, ids, s2a, ip paris)","statistics theory","in this paper we develop a novel nonparametric framework to test the independence of two random variables $\mathbf{x}$ and $\mathbf{y}$ with unknown respective marginals $h(dx)$ and $g(dy)$ and joint distribution $f(dx dy)$, based on {\it receiver operating characteristic} (roc) analysis and bipartite ranking. the rationale behind our approach relies on the fact that, the independence hypothesis $\mathcal{h}\_0$ is necessarily false as soon as the optimal scoring function related to the pair of distributions $(h\otimes g,\; f)$, obtained from a bipartite ranking algorithm, has a roc curve that deviates from the main diagonal of the unit square.we consider a wide class of rank statistics encompassing many ways of deviating from the diagonal in the roc space to build tests of independence. beyond its great flexibility, this new method has theoretical properties that far surpass those of its competitors. nonasymptotic bounds for the two types of testing errors are established. from an empirical perspective, the novel procedure we promote in this paper exhibits a remarkable ability to detect small departures, of various types, from the null assumption $\mathcal{h}_0$, even in high dimension, as supported by the numerical experiments presented here.",2024-03-12
"84",84,"experimental comparison of ensemble methods and time-to-event analysis models through integrated brier score and concordance index","camila fernandez (lpsm), chung shue chen, chen pierre gaillard, alonso silva","machine learning","time-to-event analysis is a branch of statistics that has increased in popularity during the last decades due to its many application fields, such as predictive maintenance, customer churn prediction and population lifetime estimation. in this paper, we review and compare the performance of several prediction models for time-to-event analysis. these consist of semi-parametric and parametric statistical models, in addition to machine learning approaches. our study is carried out on three datasets and evaluated in two different scores (the integrated brier score and concordance index). moreover, we show how ensemble methods, which surprisingly have not yet been much studied in time-to-event analysis, can improve the prediction accuracy and enhance the robustness of the prediction performance. we conclude the analysis with a simulation experiment in which we evaluate the factors influencing the performance ranking of the methods using both scores.",2024-03-12
"85",85,"a tutorial on multi-view autoencoders using the multi-view-ae library","ana lawry aguila, andre altmann","machine learning","there has been a growing interest in recent years in modelling multiple modalities (or views) of data to for example, understand the relationship between modalities or to generate missing data. multi-view autoencoders have gained significant traction for their adaptability and versatility in modelling multi-modal data, demonstrating an ability to tailor their approach to suit the characteristics of the data at hand. however, most multi-view autoencoders have inconsistent notation and are often implemented using different coding frameworks. to address this, we present a unified mathematical framework for multi-view autoencoders, consolidating their formulations. moreover, we offer insights into the motivation and theoretical advantages of each model. to facilitate accessibility and practical use, we extend the documentation and functionality of the previously introduced \texttt{multi-view-ae} library. this library offers python implementations of numerous multi-view autoencoder models, presented within a user-friendly framework. through benchmarking experiments, we evaluate our implementations against previous ones, demonstrating comparable or superior performance. this work aims to establish a cohesive foundation for multi-modal modelling, serving as a valuable educational resource in the field.",2024-03-12
"86",86,"fast, accurate and lightweight sequential simulation-based inference using gaussian locally linear mappings","henrik h√§ggstr√∂m, pedro l. c. rodrigues, geoffroy oudoumanessah, florence forbes, umberto picchini","machine learning","bayesian inference for complex models with an intractable likelihood can be tackled using algorithms performing many calls to computer simulators. these approaches are collectively known as ""simulation-based inference"" (sbi). recent sbi methods have made use of neural networks (nn) to provide approximate, yet expressive constructs for the unavailable likelihood function and the posterior distribution. however, they do not generally achieve an optimal trade-off between accuracy and computational demand. in this work, we propose an alternative that provides both approximations to the likelihood and the posterior distribution, using structured mixtures of probability distributions. our approach produces accurate posterior inference when compared to state-of-the-art nn-based sbi methods, while exhibiting a much smaller computational footprint. we illustrate our results on several benchmark models from the sbi literature.",2024-03-12
"87",87,"ab-initio variational wave functions for the time-dependent many-electron schr√∂dinger equation","jannes nys, gabriel pescia, giuseppe carleo","strongly correlated electrons","describing the dynamics of many-electron quantum systems is crucial for applications such as predicting electronic structures in quantum chemistry, the properties of condensed matter systems, and the behaviors of complex materials. however, the real-time evolution of non-equilibrium quantum electronic systems poses a significant challenge for theoretical and computational approaches, due to the system's exploration of a vast configuration space. this work introduces a variational approach for fermionic time-dependent wave functions, surpassing mean-field approximations by capturing many-body correlations. the proposed methodology involves parameterizing the time-evolving quantum state, enabling the approximation of the state's evolution. to account for electron correlations, we employ time-dependent jastrow factors and backflow transformations. we also show that we can incorporate neural networks to parameterize these functions. the time-dependent variational monte carlo technique is employed to efficiently compute the optimal time-dependent parameters. the approach is demonstrated in three distinct systems: the solvable harmonic interaction model, the dynamics of a diatomic molecule in intense laser fields, and a quenched quantum dot. in all cases, we show clear signatures of many-body correlations in the dynamics not captured by mean-field methods. the results showcase the ability of our variational approach to accurately capture the time evolution of quantum states, providing insight into the quantum dynamics of interacting electronic systems, beyond the capabilities of mean-field.",2024-03-12
"88",88,"proxy methods for domain adaptation","katherine tsai, stephen r. pfohl, olawale salaudeen, nicole chiou, matt j. kusner, alexander d'amour, sanmi koyejo, arthur gretton","machine learning","we study the problem of domain adaptation under distribution shift, where the shift is due to a change in the distribution of an unobserved, latent variable that confounds both the covariates and the labels. in this setting, neither the covariate shift nor the label shift assumptions apply. our approach to adaptation employs proximal causal learning, a technique for estimating causal effects in settings where proxies of unobserved confounders are available. we demonstrate that proxy variables allow for adaptation to distribution shift without explicitly recovering or modeling latent variables. we consider two settings, (i) concept bottleneck: an additional ''concept'' variable is observed that mediates the relationship between the covariates and labels; (ii) multi-domain: training data from multiple source domains is available, where each source domain exhibits a different distribution over the latent confounder. we develop a two-stage kernel estimation approach to adapt to complex distribution shifts in both settings. in our experiments, we show that our approach outperforms other methods, notably those which explicitly recover the latent confounder.",2024-03-12
"89",89,"knowledge transfer across multiple principal component analysis studies","zeyu li, kangxiang qin, yong he, wang zhou, xinsheng zhang","machine learning","transfer learning has aroused great interest in the statistical community. in this article, we focus on knowledge transfer for unsupervised learning tasks in contrast to the supervised learning tasks in the literature. given the transferable source populations, we propose a two-step transfer learning algorithm to extract useful information from multiple source principal component analysis (pca) studies, thereby enhancing estimation accuracy for the target pca task. in the first step, we integrate the shared subspace information across multiple studies by a proposed method named as grassmannian barycenter, instead of directly performing pca on the pooled dataset. the proposed grassmannian barycenter method enjoys robustness and computational advantages in more general cases. then the resulting estimator for the shared subspace from the first step is further utilized to estimate the target private subspace in the second step. our theoretical analysis credits the gain of knowledge transfer between pca studies to the enlarged eigenvalue gap, which is different from the existing supervised transfer learning tasks where sparsity plays the central role. in addition, we prove that the bilinear forms of the empirical spectral projectors have asymptotic normality under weaker eigenvalue gap conditions after knowledge transfer. when the set of informativesources is unknown, we endow our algorithm with the capability of useful dataset selection by solving a rectified optimization problem on the grassmann manifold, which in turn leads to a computationally friendly rectified grassmannian k-means procedure. in the end, extensive numerical simulation results and a real data case concerning activity recognition are reported to support our theoretical claims and to illustrate the empirical usefulness of the proposed transfer learning methods.",2024-03-12
"90",90,"input data adaptive learning (idal) for sub-acute ischemic stroke lesion segmentation","michael g√∂tz, christian weber, christoph kolb, klaus maier-hein","image and video processing","in machine learning larger databases are usually associated with higher classification accuracy due to better generalization. this generalization may lead to non-optimal classifiers in some medical applications with highly variable expressions of pathologies. this paper presents a method for learning from a large training base by adaptively selecting optimal training samples for given input data. in this way heterogeneous databases are supported two-fold. first, by being able to deal with sparsely annotated data allows a quick inclusion of new data set and second, by training an input-dependent classifier. the proposed approach is evaluated using the siss challenge. the proposed algorithm leads to a significant improvement of the classification accuracy.",2024-03-12
"91",91,"learning-augmented algorithms with explicit predictors","marek elias, haim kaplan, yishay mansour, shay moran","machine learning","recent advances in algorithmic design show how to utilize predictions obtained by machine learning models from past and present data. these approaches have demonstrated an enhancement in performance when the predictions are accurate, while also ensuring robustness by providing worst-case guarantees when predictions fail. in this paper we focus on online problems; prior research in this context was focused on a paradigm where the predictor is pre-trained on past data and then used as a black box (to get the predictions it was trained for). in contrast, in this work, we unpack the predictor and integrate the learning problem it gives rise for within the algorithmic challenge. in particular we allow the predictor to learn as it receives larger parts of the input, with the ultimate goal of designing online learning algorithms specifically tailored for the algorithmic task at hand. adopting this perspective, we focus on a number of fundamental problems, including caching and scheduling, which have been well-studied in the black-box setting. for each of the problems we consider, we introduce new algorithms that take advantage of explicit learning algorithms which we carefully design towards optimizing the overall performance. we demonstrate the potential of our approach by deriving performance bounds which improve over those established in previous work.",2024-03-12
"92",92,"accelerated inference and reduced forgetting: the dual benefits of early-exit networks in continual learning","filip szatkowski, fei yang, bart≈Çomiej twardowski, tomasz trzci≈Ñski, joost van de weijer","machine learning","driven by the demand for energy-efficient employment of deep neural networks, early-exit methods have experienced a notable increase in research attention. these strategies allow for swift predictions by making decisions early in the network, thereby conserving computation time and resources. however, so far the early-exit networks have only been developed for stationary data distributions, which restricts their application in real-world scenarios with continuous non-stationary data. this study aims to explore the continual learning of the early-exit networks. we adapt existing continual learning methods to fit with early-exit architectures and investigate their behavior in the continual setting. we notice that early network layers exhibit reduced forgetting and can outperform standard networks even when using significantly fewer resources. furthermore, we analyze the impact of task-recency bias on early-exit inference and propose task-wise logits correction (tlc), a simple method that equalizes this bias and improves the network performance for every given compute budget in the class-incremental setting. we assess the accuracy and computational cost of various continual learning techniques enhanced with early-exits and tlc across standard class-incremental learning benchmarks such as 10 split cifar100 and imagenetsubset and show that tlc can achieve the accuracy of the standard methods using less than 70\% of their computations. moreover, at full computational budget, our method outperforms the accuracy of the standard counterparts by up to 15 percentage points. our research underscores the inherent synergy between early-exit networks and continual learning, emphasizing their practical utility in resource-constrained environments.",2024-03-12
"93",93,"smalltolarge (s2l): scalable data selection for fine-tuning large language models by summarizing training trajectories of small models","yu yang, siddhartha mishra, jeffrey n chiang, baharan mirzasoleiman","computation and language","despite the effectiveness of data selection for large language models (llms) during pretraining and instruction fine-tuning phases, improving data efficiency in supervised fine-tuning (sft) for specialized domains poses significant challenges due to the complexity of fine-tuning data. to bridge this gap, we introduce an effective and scalable data selection method for sft, smalltolarge (s2l), which leverages training trajectories from small models to guide the data selection for larger models. we demonstrate through extensive experiments that s2l significantly improves data efficiency in sft for mathematical problem-solving, reducing the training data to just 11% of the original mathinstruct dataset (yue et al., 2023) to match full dataset performance while outperforming state-of-the-art data selection algorithms by an average of 4.7% across 6 in- and out-domain evaluation datasets. remarkably, selecting only 50k data for sft, s2l achieves a 32.7% accuracy on the most challenging math (hendrycks et al., 2021) benchmark, improving phi-2 (li et al., 2023b) by 16.6%. in clinical text summarization on the mimic-iii dataset (johnson et al., 2016), s2l again outperforms training on the full dataset using only 50% of the data. notably, s2l can perform data selection using a reference model 40x smaller than the target model, proportionally reducing the cost of data selection.",2024-03-12
"94",94,"hallmarks of optimization trajectories in neural networks and llms: the lengths, bends, and dead ends","sidak pal singh, bobby he, thomas hofmann, bernhard sch√∂lkopf","machine learning","we propose a fresh take on understanding the mechanisms of neural networks by analyzing the rich structure of parameters contained within their optimization trajectories. towards this end, we introduce some natural notions of the complexity of optimization trajectories, both qualitative and quantitative, which reveal the inherent nuance and interplay involved between various optimization choices, such as momentum, weight decay, and batch size. we use them to provide key hallmarks about the nature of optimization in deep neural networks: when it goes right, and when it finds itself in a dead end. further, thanks to our trajectory perspective, we uncover an intertwined behaviour of momentum and weight decay that promotes directional exploration, as well as a directional regularization behaviour of some others. we perform experiments over large-scale vision and language settings, including large language models (llms) with up to 12 billion parameters, to demonstrate the value of our approach.",2024-03-12
"95",95,"svd-llm: truncation-aware singular value decomposition for large language model compression","xin wang, yu zheng, zhongwei wan, mi zhang","computation and language","the advancements in large language models (llms) have been hindered by their substantial sizes, which necessitate llm compression methods for practical deployment. singular value decomposition (svd) offers a promising solution for llm compression. however, state-of-the-art svd-based llm compression methods have two key limitations: truncating smaller singular values may lead to higher compression loss, and the lack of update on the remaining model parameters after svd truncation. in this work, we propose svd-llm, a new svd-based llm compression method that addresses the limitations of existing methods. svd-llm incorporates a truncation-aware data whitening strategy to ensure a direct mapping between singular values and compression loss. moreover, svd-llm adopts a layer-wise closed-form model parameter update strategy to compensate for accuracy degradation caused by svd truncation. we evaluate svd-llm on a total of 11 datasets and seven models from three different llm families at four different scales. our results demonstrate the superiority of svd-llm over state-of-the-arts, especially at high model compression ratios. the source code is available at this https url.",2024-03-12
"96",96,"entropy is not enough for test-time adaptation: from the perspective of disentangled factors","jonghyun lee, dahuin jung, saehyung lee, junsung park, juhyeon shin, uiwon hwang, sungroh yoon","computer vision and pattern recognition","test-time adaptation (tta) fine-tunes pre-trained deep neural networks for unseen test data. the primary challenge of tta is limited access to the entire test dataset during online updates, causing error accumulation. to mitigate it, tta methods have utilized the model output's entropy as a confidence metric that aims to determine which samples have a lower likelihood of causing error. through experimental studies, however, we observed the unreliability of entropy as a confidence metric for tta under biased scenarios and theoretically revealed that it stems from the neglect of the influence of latent disentangled factors of data on predictions. building upon these findings, we introduce a novel tta method named destroy your object (deyo), which leverages a newly proposed confidence metric named pseudo-label probability difference (plpd). plpd quantifies the influence of the shape of an object on prediction by measuring the difference between predictions before and after applying an object-destructive transformation. deyo consists of sample selection and sample weighting, which employ entropy and plpd concurrently. for robust adaptation, deyo prioritizes samples that dominantly incorporate shape information when making predictions. our extensive experiments demonstrate the consistent superiority of deyo over baseline methods across various scenarios, including biased and wild. project page is publicly available at this https url.",2024-03-12
"97",97,"challenging forgets: unveiling the worst-case forget sets in machine unlearning","chongyu fan, jiancheng liu, alfred hero, sijia liu","machine learning","the trustworthy machine learning (ml) community is increasingly recognizing the crucial need for models capable of selectively 'unlearning' data points after training. this leads to the problem of machine unlearning (mu), aiming to eliminate the influence of chosen data points on model performance, while still maintaining the model's utility post-unlearning. despite various mu methods for data influence erasure, evaluations have largely focused on random data forgetting, ignoring the vital inquiry into which subset should be chosen to truly gauge the authenticity of unlearning performance. to tackle this issue, we introduce a new evaluative angle for mu from an adversarial viewpoint. we propose identifying the data subset that presents the most significant challenge for influence erasure, i.e., pinpointing the worst-case forget set. utilizing a bi-level optimization principle, we amplify unlearning challenges at the upper optimization level to emulate worst-case scenarios, while simultaneously engaging in standard training and unlearning at the lower level, achieving a balance between data influence erasure and model utility. our proposal offers a worst-case evaluation of mu's resilience and effectiveness. through extensive experiments across different datasets (including cifar-10, 100, celeba, tiny imagenet, and imagenet) and models (including both image classifiers and generative models), we expose critical pros and cons in existing (approximate) unlearning strategies. our results illuminate the complex challenges of mu in practice, guiding the future development of more accurate and robust unlearning algorithms. the code is available at this https url.",2024-03-12
"98",98,"premonition: using generative models to preempt future data changes in continual learning","mark d. mcdonnell, dong gong, ehsan abbasnejad, anton van den hengel","computer vision and pattern recognition","continual learning requires a model to adapt to ongoing changes in the data distribution, and often to the set of tasks to be performed. it is rare, however, that the data and task changes are completely unpredictable. given a description of an overarching goal or data theme, which we call a realm, humans can often guess what concepts are associated with it. we show here that the combination of a large language model and an image generation model can similarly provide useful premonitions as to how a continual learning challenge might develop over time. we use the large language model to generate text descriptions of semantically related classes that might potentially appear in the data stream in future. these descriptions are then rendered using stable diffusion to generate new labelled image samples. the resulting synthetic dataset is employed for supervised pre-training, but is discarded prior to commencing continual learning, along with the pre-training classification head. we find that the backbone of our pre-trained networks can learn representations useful for the downstream continual learning problem, thus becoming a valuable input to any existing continual learning method. although there are complexities arising from the domain gap between real and synthetic images, we show that pre-training models in this manner improves multiple class incremenal learning (cil) methods on fine-grained image classification benchmarks. supporting code can be found at this https url.",2024-03-12
"99",99,"graph unlearning with efficient partial retraining","jiahao zhang, lin wang, shijie wang, wenqi fan","machine learning","graph neural networks (gnns) have achieved remarkable success in various real-world applications. however, gnns may be trained on undesirable graph data, which can degrade their performance and reliability. to enable trained gnns to efficiently unlearn unwanted data, a desirable solution is retraining-based graph unlearning, which partitions the training graph into subgraphs and trains sub-models on them, allowing fast unlearning through partial retraining. however, the graph partition process causes information loss in the training graph, resulting in the low model utility of sub-gnn models. in this paper, we propose graphrevoker, a novel graph unlearning framework that better maintains the model utility of unlearnable gnns. specifically, we preserve the graph property with graph property-aware sharding and effectively aggregate the sub-gnn models for prediction with graph contrastive sub-model aggregation. we conduct extensive experiments to demonstrate the superiority of our proposed approach.",2024-03-12
"100",100,"im-unpack: training and inference with arbitrarily low precision integers","zhanpeng zeng, karthikeyan sankaralingam, vikas singh","machine learning","general matrix multiply (gemm) is a central operation in deep learning and corresponds to the largest chunk of the compute footprint. therefore, improving its efficiency is an active topic of ongoing research. a popular strategy is the use of low bit-width integers to approximate the original entries in a matrix. this allows efficiency gains, but often requires sophisticated techniques to control the rounding error incurred. in this work, we first verify/check that when the low bit-width restriction is removed, for a variety of transformer-based models, whether integers are sufficient for all gemms need -- for {\em both} training and inference stages, and can achieve parity with floating point counterparts. no sophisticated techniques are needed. we find that while a large majority of entries in matrices (encountered in such models) can be easily represented by {\em low} bit-width integers, the existence of a few heavy hitter entries make it difficult to achieve efficiency gains via the exclusive use of low bit-width gemms alone. to address this issue, we develop a simple algorithm, integer matrix unpacking (im-unpack), to {\em unpack} a matrix with large integer entries into a larger matrix whose entries all lie within the representable range of arbitrarily low bit-width integers. this allows {\em equivalence} with the original gemm, i.e., the exact result can be obtained using purely low bit-width integer gemms. this comes at the cost of additional operations -- we show that for many popular models, this overhead is quite small.",2024-03-12
"101",101,"list: learning to index spatio-textual data for embedding based spatial keyword queries","ziqi yin, shanshan feng, shang liu, gao cong, yew soon ong, bin cui","information retrieval","with the proliferation of spatio-textual data, top-k knn spatial keyword queries (tkqs), which return a list of objects based on a ranking function that evaluates both spatial and textual relevance, have found many real-life applications. existing geo-textual indexes for tkqs use traditional retrieval models like bm25 to compute text relevance and usually exploit a simple linear function to compute spatial relevance, but its effectiveness is limited. to improve effectiveness, several deep learning models have recently been proposed, but they suffer severe efficiency issues. to the best of our knowledge, there are no efficient indexes specifically designed to accelerate the top-k search process for these deep learning models. to tackle these issues, we propose a novel technique, which learns to index the spatio-textual data for answering embedding based spatial keyword queries (called list). list is featured with two novel components. firstly, we propose a lightweight and effective relevance model that is capable of learning both textual and spatial relevance. secondly, we introduce a novel machine learning based approximate nearest neighbor search (anns) index, which utilizes a new learning-to-cluster technique to group relevant queries and objects together while separating irrelevant queries and objects. two key challenges in building an effective and efficient index are the absence of high-quality labels and unbalanced clustering results. we develop a novel pseudo-label generation technique to address the two challenges. experimental results show that list significantly outperforms state-of-the-art methods on effectiveness, with improvements up to 19.21% and 12.79% in terms of ndcg@1 and recall@10, and is three orders of magnitude faster than the most effective baseline.",2024-03-12
"102",102,"unknown domain inconsistency minimization for domain generalization","seungjae shin, heesun bae, byeonghu na, yoon-yeong kim, il-chul moon","machine learning","the objective of domain generalization (dg) is to enhance the transferability of the model learned from a source domain to unobserved domains. to prevent overfitting to a specific domain, sharpness-aware minimization (sam) reduces source domain's loss sharpness. although sam variants have delivered significant improvements in dg, we highlight that there's still potential for improvement in generalizing to unknown domains through the exploration on data space. this paper introduces an objective rooted in both parameter and data perturbed regions for domain generalization, coined unknown domain inconsistency minimization (udim). udim reduces the loss landscape inconsistency between source domain and unknown domains. as unknown domains are inaccessible, these domains are empirically crafted by perturbing instances from the source domain dataset. in particular, by aligning the loss landscape acquired in the source domain to the loss landscape of perturbed domains, we expect to achieve generalization grounded on these flat minima for the unknown domains. theoretically, we validate that merging sam optimization with the udim objective establishes an upper bound for the true objective of the dg task. in an empirical aspect, udim consistently outperforms sam variants across multiple dg benchmark datasets. notably, udim shows statistically significant improvements in scenarios with more restrictive domain information, underscoring udim's generalization capability in unseen domains. our code is available at \url{this https url}.",2024-03-12
"103",103,"a question-centric multi-experts contrastive learning framework for improving the accuracy and interpretability of deep sequential knowledge tracing models","hengyuan zhang, zitao liu, chenming shang, dawei li, yong jiang","computers and society","knowledge tracing (kt) plays a crucial role in predicting students' future performance by analyzing their historical learning processes. deep neural networks (dnns) have shown great potential in solving the kt problem. however, there still exist some important challenges when applying deep learning techniques to model the kt process. the first challenge lies in taking the individual information of the question into modeling. this is crucial because, despite questions sharing the same knowledge component (kc), students' knowledge acquisition on homogeneous questions can vary significantly. the second challenge lies in interpreting the prediction results from existing deep learning-based kt models. in real-world applications, while it may not be necessary to have complete transparency and interpretability of the model parameters, it is crucial to present the model's prediction results in a manner that teachers find interpretable. this makes teachers accept the rationale behind the prediction results and utilize them to design teaching activities and tailored learning strategies for students. however, the inherent black-box nature of deep learning techniques often poses a hurdle for teachers to fully embrace the model's prediction results. to address these challenges, we propose a question-centric multi-experts contrastive learning framework for kt called q-mckt.",2024-03-12
"104",104,"approaching rate-distortion limits in neural compression with lattice transform coding","eric lei, hamed hassani, shirin saeedi bidokhti","information theory","neural compression has brought tremendous progress in designing lossy compressors with good rate-distortion (rd) performance at low complexity. thus far, neural compression design involves transforming the source to a latent vector, which is then rounded to integers and entropy coded. while this approach has been shown to be optimal in a one-shot sense on certain sources, we show that it is highly sub-optimal on i.i.d. sequences, and in fact always recovers scalar quantization of the original source sequence. we demonstrate that the sub-optimality is due to the choice of quantization scheme in the latent space, and not the transform design. by employing lattice quantization instead of scalar quantization in the latent space, we demonstrate that lattice transform coding (ltc) is able to recover optimal vector quantization at various dimensions and approach the asymptotically-achievable rate-distortion function at reasonable complexity. on general vector sources, ltc improves upon standard neural compressors in one-shot coding performance. ltc also enables neural compressors that perform block coding on i.i.d. vector sources, which yields coding gain over optimal one-shot coding.",2024-03-12
"105",105,"customizable avatars with dynamic facial action coded expressions (cadyface) for improved user engagement","megan a. witherow, crystal butler, winston j. shields, furkan ilgin, norou diawara, janice keener, john w. harrington, khan m. iftekharuddin","human-computer interaction","customizable 3d avatar-based facial expression stimuli may improve user engagement in behavioral biomarker discovery and therapeutic intervention for autism, alzheimer's disease, facial palsy, and more. however, there is a lack of customizable avatar-based stimuli with facial action coding system (facs) action unit (au) labels. therefore, this study focuses on (1) facs-labeled, customizable avatar-based expression stimuli for maintaining subjects' engagement, (2) learning-based measurements that quantify subjects' facial responses to such stimuli, and (3) validation of constructs represented by stimulus-measurement pairs. we propose customizable avatars with dynamic facial action coded expressions (cadyface) labeled with aus by a certified facs expert. to measure subjects' aus in response to cadyface, we propose a novel beta-guided correlation and multi-task expression learning neural network (become-net) for multi-label au detection. the beta-guided correlation loss encourages feature correlation with aus while discouraging correlation with subject identities for improved generalization. we train become-net for unilateral and bilateral au detection and compare with state-of-the-art approaches. to assess construct validity of cadyface and become-net, twenty healthy adult volunteers complete expression recognition and mimicry tasks in an online feasibility study while webcam-based eye-tracking and video are collected. we test validity of multiple constructs, including face preference during recognition and aus during mimicry.",2024-03-12
"106",106,"knowledge graph large language model (kg-llm) for link prediction","dong shu, tianle chen, mingyu jin, yiting zhang, mengnan du, yongfeng zhang","computation and language","the task of predicting multiple links within knowledge graphs (kgs) stands as a challenge in the field of knowledge graph analysis, a challenge increasingly resolvable due to advancements in natural language processing (nlp) and kg embedding techniques. this paper introduces a novel methodology, the knowledge graph large language model framework (kg-llm), which leverages pivotal nlp paradigms, including chain-of-thought (cot) prompting and in-context learning (icl), to enhance multi-hop link prediction in kgs. by converting the kg to a cot prompt, our framework is designed to discern and learn the latent representations of entities and their interrelations. to show the efficacy of the kg-llm framework, we fine-tune three leading large language models (llms) within this framework, employing both non-icl and icl tasks for a comprehensive evaluation. further, we explore the framework's potential to provide llms with zero-shot capabilities for handling previously unseen prompts. our experimental findings discover that integrating icl and cot not only augments the performance of our approach but also significantly boosts the models' generalization capacity, thereby ensuring more precise predictions in unfamiliar scenarios.",2024-03-12
"107",107,"how does promoting the minority fraction affect generalization? a theoretical study of the one-hidden-layer neural network on group imbalance","hongkang li, shuai zhang, yihua zhang, meng wang, sijia liu, pin-yu chen","machine learning","group imbalance has been a known problem in empirical risk minimization (erm), where the achieved high average accuracy is accompanied by low accuracy in a minority group. despite algorithmic efforts to improve the minority group accuracy, a theoretical generalization analysis of erm on individual groups remains elusive. by formulating the group imbalance problem with the gaussian mixture model, this paper quantifies the impact of individual groups on the sample complexity, the convergence rate, and the average and group-level testing performance. although our theoretical framework is centered on binary classification using a one-hidden-layer neural network, to the best of our knowledge, we provide the first theoretical analysis of the group-level generalization of erm in addition to the commonly studied average generalization performance. sample insights of our theoretical results include that when all group-level co-variance is in the medium regime and all mean are close to zero, the learning performance is most desirable in the sense of a small sample complexity, a fast training rate, and a high average and group-level testing accuracy. moreover, we show that increasing the fraction of the minority group in the training data does not necessarily improve the generalization performance of the minority group. our theoretical results are validated on both synthetic and empirical datasets, such as celeba and cifar-10 in image classification.",2024-03-12
"108",108,"reinforced sequential decision-making for sepsis treatment: the posnegdm framework with mortality classifier and transformer","dipesh tamboli, jiayu chen, kiran pranesh jotheeswaran, denny yu, vaneet aggarwal","machine learning","sepsis, a life-threatening condition triggered by the body's exaggerated response to infection, demands urgent intervention to prevent severe complications. existing machine learning methods for managing sepsis struggle in offline scenarios, exhibiting suboptimal performance with survival rates below 50%. this paper introduces the posnegdm -- ``reinforcement learning with positive and negative demonstrations for sequential decision-making"" framework utilizing an innovative transformer-based model and a feedback reinforcer to replicate expert actions while considering individual patient characteristics. a mortality classifier with 96.7\% accuracy guides treatment decisions towards positive outcomes. the posnegdm framework significantly improves patient survival, saving 97.39% of patients, outperforming established machine learning algorithms (decision transformer and behavioral cloning) with survival rates of 33.4% and 43.5%, respectively. additionally, ablation studies underscore the critical role of the transformer-based decision maker and the integration of a mortality classifier in enhancing overall survival rates. in summary, our proposed approach presents a promising avenue for enhancing sepsis treatment outcomes, contributing to improved patient care and reduced healthcare costs.",2024-03-12
"109",109,"verification-aided learning of neural network barrier functions with termination guarantees","shaoru chen, lekan molu, mahyar fazlyab","machine learning","barrier functions are a general framework for establishing a safety guarantee for a system. however, there is no general method for finding these functions. to address this shortcoming, recent approaches use self-supervised learning techniques to learn these functions using training data that are periodically generated by a verification procedure, leading to a verification-aided learning framework. despite its immense potential in automating barrier function synthesis, the verification-aided learning framework does not have termination guarantees and may suffer from a low success rate of finding a valid barrier function in practice. in this paper, we propose a holistic approach to address these drawbacks. with a convex formulation of the barrier function synthesis, we propose to first learn an empirically well-behaved nn basis function and then apply a fine-tuning algorithm that exploits the convexity and counterexamples from the verification failure to find a valid barrier function with finite-step termination guarantees: if there exist valid barrier functions, the fine-tuning algorithm is guaranteed to find one in a finite number of iterations. we demonstrate that our fine-tuning method can significantly boost the performance of the verification-aided learning framework on examples of different scales and using various neural network verifiers.",2024-03-12
"110",110,"taming pre-trained llms for generalised time series forecasting via cross-modal knowledge distillation","peiyuan liu, hang guo, tao dai, naiqi li, jigang bao, xudong ren, yong jiang, shu-tao xia","machine learning","multivariate time series forecasting has recently gained great success with the rapid growth of deep learning models. however, existing approaches usually train models from scratch using limited temporal data, preventing their generalization. recently, with the surge of the large language models (llms), several works have attempted to introduce llms into time series forecasting. despite promising results, these methods directly take time series as the input to llms, ignoring the inherent modality gap between temporal and text data. in this work, we propose a novel large language models and time series alignment framework, dubbed llata, to fully unleash the potentials of llms in the time series forecasting challenge. based on cross-modal knowledge distillation, the proposed method exploits both input-agnostic static knowledge and input-dependent dynamic knowledge in pre-trained llms. in this way, it empowers the forecasting model with favorable performance as well as strong generalization abilities. extensive experiments demonstrate the proposed method establishes a new state of the art for both long- and short-term forecasting. code is available at \url{this https url}.",2024-03-12
"111",111,"graph data condensation via self-expressive graph structure reconstruction","zhanyu liu, chaolv zeng, guanjie zheng","machine learning","with the increasing demands of training graph neural networks (gnns) on large-scale graphs, graph data condensation has emerged as a critical technique to relieve the storage and time costs during the training phase. it aims to condense the original large-scale graph to a much smaller synthetic graph while preserving the essential information necessary for efficiently training a downstream gnn. however, existing methods concentrate either on optimizing node features exclusively or endeavor to independently learn node features and the graph structure generator. they could not explicitly leverage the information of the original graph structure and failed to construct an interpretable graph structure for the synthetic dataset. to address these issues, we introduce a novel framework named \textbf{g}raph data \textbf{c}ondensation via \textbf{s}elf-expressive graph structure \textbf{r}econstruction (\textbf{gcsr}). our method stands out by (1) explicitly incorporating the original graph structure into the condensing process and (2) capturing the nuanced interdependencies between the condensed nodes by reconstructing an interpretable self-expressive graph structure. extensive experiments and comprehensive analysis validate the efficacy of the proposed method across diverse gnn models and datasets. our code is available at this https url",2024-03-12
"112",112,"a framework for cost-effective and self-adaptive llm shaking and recovery mechanism","zhiyu chen, yu li, suochao zhang, jingbo zhou, jiwen zhou, chenfu bao, dianhai yu","cryptography and security","as large language models (llms) gain great success in real-world applications, an increasing number of users are seeking to develop and deploy their customized llms through cloud services. nonetheless, in some specific domains, there are still concerns regarding cost and trade-offs between privacy issues and accuracy. in this study, we introduce a cost-effective and self-adaptive llm shaking tuning and recovery mechanism, named cyphertalk. with carefully designed horizontal and vertical shaking operators, we can achieve comparable accuracy results with sota privacy-preserving llm schemes using cryptography-based or differential privacy-based methods. experiments also show that with the cyphertalk framework, users can achieve reliable accuracy when using optimized shaking operator settings. to our best knowledge, this is the first work that considers cost, and trade-off between model utility and privacy in llm scenarios.",2024-03-12
"113",113,"enhancing transfer learning with flexible nonparametric posterior sampling","hyungi lee, giung nam, edwin fong, juho lee","machine learning","transfer learning has recently shown significant performance across various tasks involving deep neural networks. in these transfer learning scenarios, the prior distribution for downstream data becomes crucial in bayesian model averaging (bma). while previous works proposed the prior over the neural network parameters centered around the pre-trained solution, such strategies have limitations when dealing with distribution shifts between upstream and downstream data. this paper introduces nonparametric transfer learning (nptl), a flexible posterior sampling method to address the distribution shift issue within the context of nonparametric learning. the nonparametric learning (npl) method is a recent approach that employs a nonparametric prior for posterior sampling, efficiently accounting for model misspecification scenarios, which is suitable for transfer learning scenarios that may involve the distribution shift between upstream and downstream tasks. through extensive empirical validations, we demonstrate that our approach surpasses other baselines in bma performance.",2024-03-12
"114",114,"anderson acceleration for iteratively reweighted $\ell_1$ algorithm","kexin li","optimization and control","iteratively reweighted l1 (irl1) algorithm is a common algorithm for solving sparse optimization problems with nonconvex and nonsmooth regularization. the development of its acceleration algorithm, often employing nesterov acceleration, has sparked significant interest. nevertheless, the convergence and complexity analysis of these acceleration algorithms consistently poses substantial challenges. recently, anderson acceleration has gained prominence owing to its exceptional performance for speeding up fixed-point iteration, with numerous recent studies applying it to gradient-based algorithms. motivated by the powerful impact of anderson acceleration, we propose an anderson-accelerated irl1 algorithm and establish its local linear convergence rate. we extend this convergence result, typically observed in smooth settings, to a nonsmooth scenario. importantly, our theoretical results do not depend on the kurdyka-lojasiewicz condition, a necessary condition in existing nesterov acceleration-based algorithms. furthermore, to ensure global convergence, we introduce a globally convergent anderson accelerated irl1 algorithm by incorporating a classical nonmonotone line search condition. experimental results indicate that our algorithm outperforms existing nesterov acceleration-based algorithms.",2024-03-12
"115",115,"near-interpolators: rapid norm growth and the trade-off between interpolation and generalization","yutong wang, rishi sonthalia, wei hu","machine learning","we study the generalization capability of nearly-interpolating linear regressors: $\boldsymbol{\beta}$'s whose training error $\tau$ is positive but small, i.e., below the noise floor. under a random matrix theoretic assumption on the data distribution and an eigendecay assumption on the data covariance matrix $\boldsymbol{\sigma}$, we demonstrate that any near-interpolator exhibits rapid norm growth: for $\tau$ fixed, $\boldsymbol{\beta}$ has squared $\ell_2$-norm $\mathbb{e}[\|{\boldsymbol{\beta}}\|_{2}^{2}] = \omega(n^{\alpha})$ where $n$ is the number of samples and $\alpha >1$ is the exponent of the eigendecay, i.e., $\lambda_i(\boldsymbol{\sigma}) \sim i^{-\alpha}$. this implies that existing data-independent norm-based bounds are necessarily loose. on the other hand, in the same regime we precisely characterize the asymptotic trade-off between interpolation and generalization. our characterization reveals that larger norm scaling exponents $\alpha$ correspond to worse trade-offs between interpolation and generalization. we verify empirically that a similar phenomenon holds for nearly-interpolating shallow neural networks.",2024-03-12
"116",116,"adaptive bounding box uncertainties via two-step conformal prediction","alexander timans, christoph-nikolas straehle, kaspar sakmann, eric nalisnick","computer vision and pattern recognition","quantifying a model's predictive uncertainty is essential for safety-critical applications such as autonomous driving. we consider quantifying such uncertainty for multi-object detection. in particular, we leverage conformal prediction to obtain uncertainty intervals with guaranteed coverage for object bounding boxes. one challenge in doing so is that bounding box predictions are conditioned on the object's class label. thus, we develop a novel two-step conformal approach that propagates uncertainty in predicted class labels into the uncertainty intervals for the bounding boxes. this broadens the validity of our conformal coverage guarantees to include incorrectly classified objects, ensuring their usefulness when maximal safety assurances are required. moreover, we investigate novel ensemble and quantile regression formulations to ensure the bounding box intervals are adaptive to object size, leading to a more balanced coverage across sizes. validating our two-step approach on real-world datasets for 2d bounding box localization, we find that desired coverage levels are satisfied with actionably tight predictive uncertainty intervals.",2024-03-12
"117",117,"advantage-aware policy optimization for offline reinforcement learning","yunpeng qing, shunyu liu, jingyuan cong, kaixuan chen, yihe zhou, mingli song","machine learning","offline reinforcement learning (rl) endeavors to leverage offline datasets to craft effective agent policy without online interaction, which imposes proper conservative constraints with the support of behavior policies to tackle the out-of-distribution (ood) problem. however, existing works often suffer from the constraint conflict issue when offline datasets are collected from multiple behavior policies, i.e., different behavior policies may exhibit inconsistent actions with distinct returns across the state space. to remedy this issue, recent advantage-weighted (aw) methods prioritize samples with high advantage values for agent training while inevitably leading to overfitting on these samples. in this paper, we introduce a novel advantage-aware policy optimization (a2po) method to explicitly construct advantage-aware policy constraints for offline learning under mixed-quality datasets. specifically, a2po employs a conditional variational auto-encoder (cvae) to disentangle the action distributions of intertwined behavior policies by modeling the advantage values of all training data as conditional variables. then the agent can follow such disentangled action distribution constraints to optimize the advantage-aware policy towards high advantage values. extensive experiments conducted on both the single-quality and mixed-quality datasets of the d4rl benchmark demonstrate that a2po yields results superior to state-of-the-art counterparts. our code will be made publicly available.",2024-03-12
"118",118,"disentangling policy from offline task representation learning via adversarial data augmentation","chengxing jia, fuxiang zhang, yi-chen li, chen-xiao gao, xu-hui liu, lei yuan, zongzhang zhang, yang yu","machine learning","offline meta-reinforcement learning (omrl) proficiently allows an agent to tackle novel tasks while solely relying on a static dataset. for precise and efficient task identification, existing omrl research suggests learning separate task representations that be incorporated with policy input, thus forming a context-based meta-policy. a major approach to train task representations is to adopt contrastive learning using multi-task offline data. the dataset typically encompasses interactions from various policies (i.e., the behavior policies), thus providing a plethora of contextual information regarding different tasks. nonetheless, amassing data from a substantial number of policies is not only impractical but also often unattainable in realistic settings. instead, we resort to a more constrained yet practical scenario, where multi-task data collection occurs with a limited number of policies. we observed that learned task representations from previous omrl methods tend to correlate spuriously with the behavior policy instead of reflecting the essential characteristics of the task, resulting in unfavorable out-of-distribution generalization. to alleviate this issue, we introduce a novel algorithm to disentangle the impact of behavior policy from task representation learning through a process called adversarial data augmentation. specifically, the objective of adversarial data augmentation is not merely to generate data analogous to offline data distribution; instead, it aims to create adversarial examples designed to confound learned task representations and lead to incorrect task identification. our experiments show that learning from such adversarial samples significantly enhances the robustness and effectiveness of the task identification process and realizes satisfactory out-of-distribution generalization.",2024-03-12
"119",119,"deep learning-assisted parallel interference cancellation for grant-free noma in machine-type communication","yongjeong oh, jaehong jo, byonghyo shim, yo-seb jeon","signal processing","in this paper, we present a novel approach for joint activity detection (ad), channel estimation (ce), and data detection (dd) in uplink grant-free non-orthogonal multiple access (noma) systems. our approach employs an iterative and parallel interference removal strategy inspired by parallel interference cancellation (pic), enhanced with deep learning to jointly tackle the ad, ce, and dd problems. based on this approach, we develop three pic frameworks, each of which is designed for either coherent or non-coherence schemes. the first framework performs joint ad and ce using received pilot signals in the coherent scheme. building upon this framework, the second framework utilizes both the received pilot and data signals for ce, further enhancing the performances of ad, ce, and dd in the coherent scheme. the third framework is designed to accommodate the non-coherent scheme involving a small number of data bits, which simultaneously performs ad and dd. through joint loss functions and interference cancellation modules, our approach supports end-to-end training, contributing to enhanced performances of ad, ce, and dd for both coherent and non-coherent schemes. simulation results demonstrate the superiority of our approach over traditional techniques, exhibiting enhanced performances of ad, ce, and dd while maintaining lower computational complexity.",2024-03-12
"120",120,"guidegen: a text-guided framework for joint ct volume and anatomical structure generation","linrui dai, rongzhao zhang, zhongzhen huang, xiaofan zhang","image and video processing","the annotation burden and extensive labor for gathering a large medical dataset with images and corresponding labels are rarely cost-effective and highly intimidating. this results in a lack of abundant training data that undermines downstream tasks and partially contributes to the challenge image analysis faces in the medical field. as a workaround, given the recent success of generative neural models, it is now possible to synthesize image datasets at a high fidelity guided by external constraints. this paper explores this possibility and presents \textbf{guidegen}: a pipeline that jointly generates ct images and tissue masks for abdominal organs and colorectal cancer conditioned on a text prompt. firstly, we introduce volumetric mask sampler to fit the discrete distribution of mask labels and generate low-resolution 3d tissue masks. secondly, our conditional image generator autoregressively generates ct slices conditioned on a corresponding mask slice to incorporate both style information and anatomical guidance. this pipeline guarantees high fidelity and variability as well as exact alignment between generated ct volumes and tissue masks. both qualitative and quantitative experiments on 3d abdominal cts demonstrate a high performance of our proposed pipeline, thereby proving our method can serve as a dataset generator and provide potential benefits to downstream tasks. it is hoped that our work will offer a promising solution on the multimodality generation of ct and its anatomical mask. our source code is publicly available at this https url.",2024-03-12
"121",121,"dataset condensation for time series classification via dual domain matching","zhanyu liu, ke hao, guanjie zheng, yanwei yu","machine learning","time series data has been demonstrated to be crucial in various research fields. the management of large quantities of time series data presents challenges in terms of deep learning tasks, particularly for training a deep neural network. recently, a technique named \textit{dataset condensation} has emerged as a solution to this problem. this technique generates a smaller synthetic dataset that has comparable performance to the full real dataset in downstream tasks such as classification. however, previous methods are primarily designed for image and graph datasets, and directly adapting them to the time series dataset leads to suboptimal performance due to their inability to effectively leverage the rich information inherent in time series data, particularly in the frequency domain. in this paper, we propose a novel framework named dataset \textit{\textbf{cond}}ensation for \textit{\textbf{t}}ime \textit{\textbf{s}}eries \textit{\textbf{c}}lassification via dual domain matching (\textbf{condtsc}) which focuses on the time series classification dataset condensation task. different from previous methods, our proposed framework aims to generate a condensed dataset that matches the surrogate objectives in both the time and frequency domains. specifically, condtsc incorporates multi-view data augmentation, dual domain training, and dual surrogate objectives to enhance the dataset condensation process in the time and frequency domains. through extensive experiments, we demonstrate the effectiveness of our proposed framework, which outperforms other baselines and learns a condensed synthetic dataset that exhibits desirable characteristics such as conforming to the distribution of the original data.",2024-03-12
"122",122,"calibrating multi-modal representations: a pursuit of group robustness without annotations","chenyu you, yifei min, weicheng dai, jasjeet s. sekhon, lawrence staib, james s. duncan","computer vision and pattern recognition","fine-tuning pre-trained vision-language models, like clip, has yielded success on diverse downstream tasks. however, several pain points persist for this paradigm: (i) directly tuning entire pre-trained models becomes both time-intensive and computationally costly. additionally, these tuned models tend to become highly specialized, limiting their practicality for real-world deployment; (ii) recent studies indicate that pre-trained vision-language classifiers may overly depend on spurious features -- patterns that correlate with the target in training data, but are not related to the true labeling function; and (iii) existing studies on mitigating the reliance on spurious features, largely based on the assumption that we can identify such features, does not provide definitive assurance for real-world applications. as a piloting study, this work focuses on exploring mitigating the reliance on spurious features for clip without using any group annotation. to this end, we systematically study the existence of spurious correlation on clip and cilp+erm. we first, following recent work on deep feature reweighting (dfr), verify that last-layer retraining can greatly improve group robustness on pretrained clip. in view of them, we advocate a lightweight representation calibration method for fine-tuning clip, by first generating a calibration set using the pretrained clip, and then calibrating representations of samples within this set through contrastive learning, all without the need for group labels. extensive experiments and in-depth visualizations on several benchmarks validate the effectiveness of our proposals, largely reducing reliance and significantly boosting the model generalization.",2024-03-12
"123",123,"tractable joint prediction and planning over discrete behavior modes for urban driving","adam villaflor, brian yang, huangyuan su, katerina fragkiadaki, john dolan, jeff schneider","robotics","significant progress has been made in training multimodal trajectory forecasting models for autonomous driving. however, effectively integrating these models with downstream planners and model-based control approaches is still an open problem. although these models have conventionally been evaluated for open-loop prediction, we show that they can be used to parameterize autoregressive closed-loop models without retraining. we consider recent trajectory prediction approaches which leverage learned anchor embeddings to predict multiple trajectories, finding that these anchor embeddings can parameterize discrete and distinct modes representing high-level driving behaviors. we propose to perform fully reactive closed-loop planning over these discrete latent modes, allowing us to tractably model the causal interactions between agents at each step. we validate our approach on a suite of more dynamic merging scenarios, finding that our approach avoids the $\textit{frozen robot problem}$ which is pervasive in conventional planners. our approach also outperforms the previous state-of-the-art in carla on challenging dense traffic scenarios when evaluated at realistic speeds.",2024-03-12
"124",124,"curry-dpo: enhancing alignment using curriculum learning & ranked preferences","pulkit pattnaik, rishabh maheshwary, kelechi ogueji, vikas yadav, sathwik tejaswi madhusudhan","computation and language","direct preference optimization (dpo) is an effective technique that leverages pairwise preference data (usually one chosen and rejected response pair per user prompt) to align llms to human preferences. in practice, multiple responses can exist for a given prompt with varying quality relative to each other. with availability of such quality ratings for multiple responses, we propose utilizing these responses to create multiple preference pairs for a given prompt. our work focuses on systematically using the constructed multiple preference pair in dpo training via curriculum learning methodology. in particular, we order these multiple pairs of preference data from easy to hard (emulating curriculum training) according to various criteria. we show detailed comparisons of our proposed approach to the standard single-pair dpo setting. our method, which we call curry-dpo consistently shows increased performance gains on mtbench, vicuna, wizardlm, and the ultrafeedback test set, highlighting its effectiveness. more specifically, curry-dpo achieves a score of 7.43 on mt-bench with zephy-7b model outperforming majority of existing llms with similar parameter size. curry-dpo also achieves the highest adjusted win rates on vicuna, wizardlm, and ultrafeedback test datasets (90.7%, 87.1%, and 87.9% respectively) in our experiments, with notable gains of upto 7.5% when compared to standard dpo technique.",2024-03-12
"125",125,"lookupffn: making transformers compute-lite for cpu inference","zhanpeng zeng, michael davies, pranav pulijala, karthikeyan sankaralingam, vikas singh","machine learning","while gpu clusters are the de facto choice for training large deep neural network (dnn) models today, several reasons including ease of workflow, security and cost have led to efforts investigating whether cpus may be viable for inference in routine use in many sectors of the industry. but the imbalance between the compute capabilities of gpus and cpus is huge. motivated by these considerations, we study a module which is a workhorse within modern dnn architectures, gemm based feed forward networks (ffns), and assess the extent to which it can be made compute- (or flop-) lite. specifically, we propose an alternative formulation (we call it lookupffn) to gemm based ffns inspired by the recent studies of using locality sensitive hashing (lsh) to approximate ffns. our formulation recasts most essential operations as a memory look-up, leveraging the trade-off between the two resources on any platform: compute and memory (since cpus offer it in abundance). for roberta language model pretraining, our formulation achieves similar performance compared to gemm based ffns, while dramatically reducing the required flop. our development is complemented with a detailed hardware profiling of strategies that will maximize efficiency -- not just on contemporary hardware but on products that will be offered in the near/medium term future. code is avaiable at \url{this https url}.",2024-03-12
"126",126,"sok: can trajectory generation combine privacy and utility?","erik buchholz, alsharif abuadbba, shuo wang, surya nepal, salil s. kanhere","cryptography and security","while location trajectories represent a valuable data source for analyses and location-based services, they can reveal sensitive information, such as political and religious preferences. differentially private publication mechanisms have been proposed to allow for analyses under rigorous privacy guarantees. however, the traditional protection schemes suffer from a limiting privacy-utility trade-off and are vulnerable to correlation and reconstruction attacks. synthetic trajectory data generation and release represent a promising alternative to protection algorithms. while initial proposals achieve remarkable utility, they fail to provide rigorous privacy guarantees. this paper proposes a framework for designing a privacy-preserving trajectory publication approach by defining five design goals, particularly stressing the importance of choosing an appropriate unit of privacy. based on this framework, we briefly discuss the existing trajectory protection approaches, emphasising their shortcomings. this work focuses on the systematisation of the state-of-the-art generative models for trajectories in the context of the proposed framework. we find that no existing solution satisfies all requirements. thus, we perform an experimental study evaluating the applicability of six sequential generative models to the trajectory domain. finally, we conclude that a generative trajectory model providing semantic guarantees remains an open research question and propose concrete next steps for future research.",2024-03-12
"127",127,"adaptive gain scheduling using reinforcement learning for quadcopter control","mike timmerman, aryan patel, tim reinhart","systems and control","the paper presents a technique using reinforcement learning (rl) to adapt the control gains of a quadcopter controller. specifically, we employed proximal policy optimization (ppo) to train a policy which adapts the gains of a cascaded feedback controller in-flight. the primary goal of this controller is to minimize tracking error while following a specified trajectory. the paper's key objective is to analyze the effectiveness of the adaptive gain policy and compare it to the performance of a static gain control algorithm, where the integral squared error and integral time squared error are used as metrics. the results show that the adaptive gain scheme achieves over 40$\%$ decrease in tracking error as compared to the static gain controller.",2024-03-12
"128",128,"which llm to play? convergence-aware online model selection with time-increasing bandits","yu xia, fang kong, tong yu, liya guo, ryan a. rossi, sungchul kim, shuai li","machine learning","web-based applications such as chatbots, search engines and news recommendations continue to grow in scale and complexity with the recent surge in the adoption of llms. online model selection has thus garnered increasing attention due to the need to choose the best model among a diverse set while balancing task reward and exploration cost. organizations faces decisions like whether to employ a costly api-based llm or a locally finetuned small llm, weighing cost against performance. traditional selection methods often evaluate every candidate model before choosing one, which are becoming impractical given the rising costs of training and finetuning llms. moreover, it is undesirable to allocate excessive resources towards exploring poor-performing models. while some recent works leverage online bandit algorithm to manage such exploration-exploitation trade-off in model selection, they tend to overlook the increasing-then-converging trend in model performances as the model is iteratively finetuned, leading to less accurate predictions and suboptimal model selections. in this paper, we propose a time-increasing bandit algorithm ti-ucb, which effectively predicts the increase of model performances due to finetuning and efficiently balances exploration and exploitation in model selection. to further capture the converging points of models, we develop a change detection mechanism by comparing consecutive increase predictions. we theoretically prove that our algorithm achieves a logarithmic regret upper bound in a typical increasing bandit setting, which implies a fast convergence rate. the advantage of our method is also empirically validated through extensive experiments on classification model selection and online selection of llms. our results highlight the importance of utilizing increasing-then-converging pattern for more efficient and economic model selection in the deployment of llms.",2024-03-11
"129",129,"tracking dynamic gaussian density with a theoretically optimal sliding window approach","yinsong wang, yu ding, shahin shahrampour","machine learning","dynamic density estimation is ubiquitous in many applications, including computer vision and signal processing. one popular method to tackle this problem is the ""sliding window"" kernel density estimator. there exist various implementations of this method that use heuristically defined weight sequences for the observed data. the weight sequence, however, is a key aspect of the estimator affecting the tracking performance significantly. in this work, we study the exact mean integrated squared error (mise) of ""sliding window"" gaussian kernel density estimators for evolving gaussian densities. we provide a principled guide for choosing the optimal weight sequence by theoretically characterizing the exact mise, which can be formulated as constrained quadratic programming. we present empirical evidence with synthetic datasets to show that our weighting scheme indeed improves the tracking performance compared to heuristic approaches.",2024-03-11
"130",130,"a multi-cohort study on prediction of acute brain dysfunction states using selective state space models","brandon silva, miguel contreras, sabyasachi bandyopadhyay, yuanfang ren, ziyuan guan, jeremy balch, kia khezeli, tezcan ozrazgat baslanti, ben shickel, azra bihorac, parisa rashidi","machine learning","assessing acute brain dysfunction (abd), including delirium and coma in the intensive care unit (icu), is a critical challenge due to its prevalence and severe implications for patient outcomes. current diagnostic methods rely on infrequent clinical observations, which can only determine a patient's abd status after onset. our research attempts to solve these problems by harnessing electronic health records (ehr) data to develop automated methods for abd prediction for patients in the icu. existing models solely predict a single state (e.g., either delirium or coma), require at least 24 hours of observation data to make predictions, do not dynamically predict fluctuating abd conditions during icu stay (typically a one-time prediction), and use small sample size, proprietary single-hospital datasets. our research fills these gaps in the existing literature by dynamically predicting delirium, coma, and mortality for 12-hour intervals throughout an icu stay and validating on two public datasets. our research also introduces the concept of dynamically predicting critical transitions from non-abd to abd and between different abd states in real time, which could be clinically more informative for the hospital staff. we compared the predictive performance of two state-of-the-art neural network models, the mamba selective state space model and the longformer transformer model. using the mamba model, we achieved a mean area under the receiving operator characteristic curve (auroc) of 0.95 on outcome prediction of abd for 12-hour intervals. the model achieves a mean auroc of 0.79 when predicting transitions between abd states. our study uses a curated dataset from the university of florida health shands hospital for internal validation and two publicly available datasets, mimic-iv and eicu, for external validation, demonstrating robustness across icu stays from 203 hospitals and 140,945 patients.",2024-03-11
"131",131,"improving prediction of students' performance in intelligent tutoring systems using attribute selection and ensembles of different multimodal data sources","w. chango, r. cerezo, m. sanchez-santillan, r. azevedo, c. romero","computers and society","the aim of this study was to predict university students' learning performance using different sources of data from an intelligent tutoring system. we collected and preprocessed data from 40 students from different multimodal sources: learning strategies from system logs, emotions from face recording videos, interaction zones from eye tracking, and test performance from final knowledge evaluation. our objective was to test whether the prediction could be improved by using attribute selection and classification ensembles. we carried out three experiments by applying six classification algorithms to numerical and discretized preprocessed multimodal data. the results show that the best predictions were produced using ensembles and selecting the best attributes approach with numerical data.",2024-02-10
"132",132,"$\mathbf{(n,k)}$-puzzle: a cost-efficient testbed for benchmarking reinforcement learning algorithms in generative language model","yufeng zhang, liyu chen, boyi liu, yingxiang yang, qiwen cui, yunzhe tao, hongxia yang","machine learning","recent advances in reinforcement learning (rl) algorithms aim to enhance the performance of language models at scale. yet, there is a noticeable absence of a cost-effective and standardized testbed tailored to evaluating and comparing these algorithms. to bridge this gap, we present a generalized version of the 24-puzzle: the $(n,k)$-puzzle, which challenges language models to reach a target value $k$ with $n$ integers. we evaluate the effectiveness of established rl algorithms such as proximal policy optimization (ppo), alongside novel approaches like identity policy optimization (ipo) and direct policy optimization (dpo).",2024-03-11
"133",133,"ups: towards foundation models for pde solving via cross-modal adaptation","junhong shen, tanya marwah, ameet talwalkar","machine learning","we introduce ups (unified pde solver), an effective and data-efficient approach to solve diverse spatiotemporal pdes defined over various domains, dimensions, and resolutions. ups unifies different pdes into a consistent representation space and processes diverse collections of pde data using a unified network architecture that combines llms with domain-specific neural operators. we train the network via a two-stage cross-modal adaptation process, leveraging ideas of modality alignment and multi-task learning. by adapting from pretrained llms and exploiting text-form meta information, we are able to use considerably fewer training samples than previous methods while obtaining strong empirical results. ups outperforms existing baselines, often by a large margin, on a wide range of 1d and 2d datasets in pdebench, achieving state-of-the-art results on 8 of 10 tasks considered. meanwhile, it is capable of few-shot transfer to different pde families, coefficients, and resolutions.",2024-03-11
"134",134,"uncertainty in graph neural networks: a survey","fangxin wang, yuqing liu, kay liu, yibo wang, sourav medya, philip s. yu","machine learning","graph neural networks (gnns) have been extensively used in various real-world applications. however, the predictive uncertainty of gnns stemming from diverse sources such as inherent randomness in data and model training errors can lead to unstable and erroneous predictions. therefore, identifying, quantifying, and utilizing uncertainty are essential to enhance the performance of the model for the downstream tasks as well as the reliability of the gnn predictions. this survey aims to provide a comprehensive overview of the gnns from the perspective of uncertainty with an emphasis on its integration in graph learning. we compare and summarize existing graph uncertainty theory and methods, alongside the corresponding downstream tasks. thereby, we bridge the gap between theory and practice, meanwhile connecting different gnn communities. moreover, our work provides valuable insights into promising directions in this field.",2024-03-11
"135",135,"monitoring ai-modified content at scale: a case study on the impact of chatgpt on ai conference peer reviews","weixin liang, zachary izzo, yaohui zhang, haley lepp, hancheng cao, xuandong zhao, lingjiao chen, haotian ye, sheng liu, zhi huang, daniel a. mcfarland, james y. zou","computation and language","we present an approach for estimating the fraction of text in a large corpus which is likely to be substantially modified or produced by a large language model (llm). our maximum likelihood model leverages expert-written and ai-generated reference texts to accurately and efficiently examine real-world llm-use at the corpus level. we apply this approach to a case study of scientific peer review in ai conferences that took place after the release of chatgpt: iclr 2024, neurips 2023, corl 2023 and emnlp 2023. our results suggest that between 6.5% and 16.9% of text submitted as peer reviews to these conferences could have been substantially modified by llms, i.e. beyond spell-checking or minor writing updates. the circumstances in which generated text occurs offer insight into user behavior: the estimated fraction of llm-generated text is higher in reviews which report lower confidence, were submitted close to the deadline, and from reviewers who are less likely to respond to author rebuttals. we also observe corpus-level trends in generated text which may be too subtle to detect at the individual level, and discuss the implications of such trends on peer review. we call for future interdisciplinary work to examine how llm use is changing our information and knowledge practices.",2024-03-11
"136",136,"study of the impact of the big data era on accounting and auditing","yuxiang sun, jingyi li, mengdie lu, zongying guo","general finance","big data revolutionizes accounting and auditing, offering deep insights but also introducing challenges like data privacy and security. with data from iot, social media, and transactions, traditional practices are evolving. professionals must adapt to these changes, utilizing ai and machine learning for efficient data analysis and anomaly detection. key to overcoming these challenges are enhanced analytics tools, continuous learning, and industry collaboration. by addressing these areas, the accounting and auditing fields can harness big data's potential while ensuring accuracy, transparency, and integrity in financial reporting. keywords: big data, accounting, audit, data privacy, ai, machine learning, transparency.",2024-03-11
"137",137,"3m-diffusion: latent multi-modal diffusion for text-guided generation of molecular graphs","huaisheng zhu, teng xiao, vasant g honavar","machine learning","generating molecules with desired properties is a critical task with broad applications in drug discovery and materials design. inspired by recent advances in large language models, there is a growing interest in using natural language descriptions of molecules to generate molecules with the desired properties. most existing methods focus on generating molecules that precisely match the text description. however, practical applications call for methods that generate diverse, and ideally novel, molecules with the desired properties. we propose 3m-diffusion, a novel multi-modal molecular graph generation method, to address this challenge. 3m-diffusion first encodes molecular graphs into a graph latent space aligned with text descriptions. it then reconstructs the molecular structure and atomic attributes based on the given text descriptions using the molecule decoder. it then learns a probabilistic mapping from the text space to the latent molecular graph space using a diffusion model. the results of our extensive experiments on several datasets demonstrate that 3m-diffusion can generate high-quality, novel and diverse molecular graphs that semantically match the textual description provided.",2024-03-11
"138",138,"don't forget what i did?: assessing client contributions in federated learning","bishwamittra ghosh, debabrota basu, fu huazhu, wang yuan, renuga kanagavelu, jiang jin peng, liu yong, goh siow mong rick, wei qingsong","machine learning","federated learning (fl) is a collaborative machine learning (ml) approach, where multiple clients participate in training an ml model without exposing the private data. fair and accurate assessment of client contributions is an important problem in fl to facilitate incentive allocation and encouraging diverse clients to participate in a unified model training. existing methods for assessing client contribution adopts co-operative game-theoretic concepts, such as shapley values, but under simplified assumptions. in this paper, we propose a history-aware game-theoretic framework, called flcontrib, to assess client contributions when a subset of (potentially non-i.i.d.) clients participate in each epoch of fl training. by exploiting the fl training process and linearity of shapley value, we develop flcontrib that yields a historical timeline of client contributions as fl training progresses over epochs. additionally, to assess client contribution under limited computational budget, we propose a scheduling procedure that considers a two-sided fairness criteria to perform expensive shapley value computation only in a subset of training epochs. in experiments, we demonstrate a controlled trade-off between the correctness and efficiency of client contributions assessed via flcontrib. to demonstrate the benefits of history-aware client contributions, we apply flcontrib to detect dishonest clients conducting data poisoning in fl training.",2024-03-11
"139",139,"advancing hyperspectral targeted alpha therapy with adversarial machine learning","jim zhao, greg leadman","medical physics","targeted alpha therapy (tat) has emerged as a promising modality for the treatment of various malignancies, leveraging the high linear energy transfer (let) and short range of alpha particles to selectively irradiate cancer cells while sparing healthy tissue. monitoring and optimizing tat delivery is crucial for its clinical success. hyper-spectral single photon imaging (hspi) presents a novel and versatile approach for the real-time assessment of tat in vivo. this study introduces a comprehensive framework for hspi in tat, encompassing spectral unmixing, quantitative dosimetry, and spatiotemporal visualization. we report the development of a dedicated hspi system tailored to alpha-emitting radionuclides, enabling the simultaneous acquisition of high-resolution spectral data and single-photon localization. utilizing advanced spectral unmixing algorithms, we demonstrate the discrimination of alpha-induced scintillation from background fluorescence, facilitating precise alpha particle tracking with adversarial machine learning.",2024-03-11
"140",140,"stochastic extragradient with random reshuffling: improved convergence for variational inequalities","konstantinos emmanouilidis, ren√© vidal, nicolas loizou","optimization and control","the stochastic extragradient (seg) method is one of the most popular algorithms for solving finite-sum min-max optimization and variational inequality problems (vips) appearing in various machine learning tasks. however, existing convergence analyses of seg focus on its with-replacement variants, while practical implementations of the method randomly reshuffle components and sequentially use them. unlike the well-studied with-replacement variants, seg with random reshuffling (seg-rr) lacks established theoretical guarantees. in this work, we provide a convergence analysis of seg-rr for three classes of vips: (i) strongly monotone, (ii) affine, and (iii) monotone. we derive conditions under which seg-rr achieves a faster convergence rate than the uniform with-replacement sampling seg. in the monotone setting, our analysis of seg-rr guarantees convergence to an arbitrary accuracy without large batch sizes, a strong requirement needed in the classical with-replacement seg. as a byproduct of our results, we provide convergence guarantees for shuffle once seg (shuffles the data only at the beginning of the algorithm) and the incremental extragradient (does not shuffle the data). we supplement our analysis with experiments validating empirically the superior performance of seg-rr over the classical with-replacement sampling seg.",2024-03-11
"141",141,"new perspectives in online contract design: heterogeneous, homogeneous, non-myopic agents and team production","shiliang zuo","computer science and game theory","this work studies the repeated principal-agent problem from an online learning perspective. the principal's goal is to learn the optimal contract that maximizes her utility through repeated interactions, without prior knowledge of the agent's type (i.e., the agent's cost and production functions). i study three different settings when the principal contracts with a $\textit{single}$ agent each round: 1. the agents are heterogeneous; 2. the agents are homogenous; 3. the principal interacts with the same agent and the agent is non-myopic. i present different approaches and techniques for designing learning algorithms in each setting. for heterogeneous agent types, i identify a condition that allows the problem to be reduced to lipschitz bandits directly. for identical agents, i give a polynomial sample complexity scheme to learn the optimal contract based on inverse game theory. for strategic non-myopic agents, i design a low strategic-regret mechanism. also, i identify a connection between linear contracts and posted-price auctions, showing the two can be reduced to one another, and give a regret lower bound on learning the optimal linear contract based on this observation. i also study a $\textit{team production}$ model. i identify a condition under which the principal's learning problem can be reformulated as solving a family of convex programs, thereby showing the optimal contract can be found efficiently.",2024-03-11
"142",142,"one category one prompt: dataset distillation using diffusion models","ali abbasi, ashkan shahbazi, hamed pirsiavash, soheil kolouri","computer vision and pattern recognition","the extensive amounts of data required for training deep neural networks pose significant challenges on storage and transmission fronts. dataset distillation has emerged as a promising technique to condense the information of massive datasets into a much smaller yet representative set of synthetic samples. however, traditional dataset distillation approaches often struggle to scale effectively with high-resolution images and more complex architectures due to the limitations in bi-level optimization. recently, several works have proposed exploiting knowledge distillation with decoupled optimization schemes to scale up dataset distillation. although these methods effectively address the scalability issue, they rely on extensive image augmentations requiring the storage of soft labels for augmented images. in this paper, we introduce dataset distillation using diffusion models (d3m) as a novel paradigm for dataset distillation, leveraging recent advancements in generative text-to-image foundation models. our approach utilizes textual inversion, a technique for fine-tuning text-to-image generative models, to create concise and informative representations for large datasets. by employing these learned text prompts, we can efficiently store and infer new samples for introducing data variability within a fixed memory budget. we show the effectiveness of our method through extensive experiments across various computer vision benchmark datasets with different memory budgets.",2024-03-11
"143",143,"exploring cluster analysis in nelore cattle visual score attribution","alexandre de oliveira bezerra, rodrigo goncalves mateus, vanessa ap. de moraes weber, fabricio de lima weber, yasmin alves de arruda, rodrigo da costa gomes, gabriel toshio hirokawa higa, hemerson pistori","image and video processing","assessing the biotype of cattle through human visual inspection is a very common and important practice in precision cattle breeding. this paper presents the results of a correlation analysis between scores produced by humans for nelore cattle and a variety of measurements that can be derived from images or other instruments. it also presents a study using the k-means algorithm to generate new ways of clustering a batch of cattle using the measurements that most correlate with the animal's body weight and visual scores.",2024-03-11
"144",144,"on the limited representational power of value functions and its links to statistical (in)efficiency","david cheikhi, daniel russo","machine learning","identifying the trade-offs between model-based and model-free methods is a central question in reinforcement learning. value-based methods offer substantial computational advantages and are sometimes just as statistically efficient as model-based methods. however, focusing on the core problem of policy evaluation, we show information about the transition dynamics may be impossible to represent in the space of value functions. we explore this through a series of case studies focused on structures that arises in many important problems. in several, there is no information loss and value-based methods are as statistically efficient as model based ones. in other closely-related examples, information loss is severe and value-based methods are severely outperformed. a deeper investigation points to the limitations of the representational power as the driver of the inefficiency, as opposed to failure in algorithm design.",2024-03-11
"145",145,"comq: a backpropagation-free algorithm for post-training quantization","aozhong zhang, zi yang, naigang wang, yingyong qin, jack xin, xin li, penghang yin","machine learning","post-training quantization (ptq) has emerged as a practical approach to compress large neural networks, making them highly efficient for deployment. however, effectively reducing these models to their low-bit counterparts without compromising the original accuracy remains a key challenge. in this paper, we propose an innovative ptq algorithm termed comq, which sequentially conducts coordinate-wise minimization of the layer-wise reconstruction errors. we consider the widely used integer quantization, where every quantized weight can be decomposed into a shared floating-point scalar and an integer bit-code. within a fixed layer, comq treats all the scaling factor(s) and bit-codes as the variables of the reconstruction error. every iteration improves this error along a single coordinate while keeping all other variables constant. comq is easy to use and requires no hyper-parameter tuning. it instead involves only dot products and rounding operations. we update these variables in a carefully designed greedy order, significantly enhancing the accuracy. comq achieves remarkable results in quantizing 4-bit vision transformers, with a negligible loss of less than 1% in top-1 accuracy. in 4-bit int quantization of convolutional neural networks, comq maintains near-lossless accuracy with a minimal drop of merely 0.3% in top-1 accuracy.",2024-03-11
"146",146,"a new machine learning dataset of bulldog nostril images for stenosis degree classification","gabriel toshio hirokawa higa, joyce katiuccia medeiros ramos carvalho, paolo brito pascoalini zanoni, gisele braziliano de andrade, hemerson pistori","image and video processing","brachycephaly, a conformation trait in some dog breeds, causes boas, a respiratory disorder that affects the health and welfare of the dogs with various symptoms. in this paper, a new annotated dataset composed of 190 images of bulldogs' nostrils is presented. three degrees of stenosis are approximately equally represented in the dataset: mild, moderate and severe stenosis. the dataset also comprises a small quantity of non stenotic nostril images. to the best of our knowledge, this is the first image dataset addressing this problem. furthermore, deep learning is investigated as an alternative to automatically infer stenosis degree using nostril images. in this work, several neural networks were tested: resnet50, mobilenetv3, densenet201, swinv2 and maxvit. for this evaluation, the problem was modeled in two different ways: first, as a three-class classification problem (mild or open, moderate, and severe); second, as a binary classification problem, with severe stenosis as target. for the multiclass classification, a maximum median f-score of 53.77\% was achieved by the mobilenetv3. for binary classification, a maximum median f-score of 72.08\% has been reached by resnet50, indicating that the problem is challenging but possibly tractable.",2024-03-11
"147",147,"fax: scalable and differentiable federated primitives in jax","keith rush, zachary charles, zachary garrett","distributed, parallel, and cluster computing","we present fax, a jax-based library designed to support large-scale distributed and federated computations in both data center and cross-device applications. fax leverages jax's sharding mechanisms to enable native targeting of tpus and state-of-the-art jax runtimes, including pathways. fax embeds building blocks for federated computations as primitives in jax. this enables three key benefits. first, fax computations can be translated to xla hlo. second, fax provides a full implementation of federated automatic differentiation, greatly simplifying the expression of federated computations. last, fax computations can be interpreted out to existing production cross-device federated compute systems. we show that fax provides an easily programmable, performant, and scalable framework for federated computations in the data center. fax is available at this https url .",2024-03-11
"148",148,"class imbalance in object detection: an experimental diagnosis and study of mitigation strategies","nieves crasto","computer vision and pattern recognition","object detection, a pivotal task in computer vision, is frequently hindered by dataset imbalances, particularly the under-explored issue of foreground-foreground class imbalance. this lack of attention to foreground-foreground class imbalance becomes even more pronounced in the context of single-stage detectors. this study introduces a benchmarking framework utilizing the yolov5 single-stage detector to address the problem of foreground-foreground class imbalance. we crafted a novel 10-class long-tailed dataset from the coco dataset, termed coco-zipf, tailored to reflect common real-world detection scenarios with a limited number of object classes. against this backdrop, we scrutinized three established techniques: sampling, loss weighing, and data augmentation. our comparative analysis reveals that sampling and loss reweighing methods, while shown to be beneficial in two-stage detector settings, do not translate as effectively in improving yolov5's performance on the coco-zipf dataset. on the other hand, data augmentation methods, specifically mosaic and mixup, significantly enhance the model's mean average precision (map), by introducing more variability and complexity into the training data. (code available: this https url)",2024-03-11
"149",149,"a slice classification neural network for automated classification of axial pet/ct slices from a multi-centric lymphoma dataset","shadab ahamed, yixi xu, ingrid bloise, joo h. o, carlos f. uribe, rahul dodhia, juan l. ferres, arman rahmim","image and video processing","automated slice classification is clinically relevant since it can be incorporated into medical image segmentation workflows as a preprocessing step that would flag slices with a higher probability of containing tumors, thereby directing physicians attention to the important slices. in this work, we train a resnet-18 network to classify axial slices of lymphoma pet/ct images (collected from two institutions) depending on whether the slice intercepted a tumor (positive slice) in the 3d image or if the slice did not (negative slice). various instances of the network were trained on 2d axial datasets created in different ways: (i) slice-level split and (ii) patient-level split; inputs of different types were used: (i) only pet slices and (ii) concatenated pet and ct slices; and different training strategies were employed: (i) center-aware (caw) and (ii) center-agnostic (cag). model performances were compared using the area under the receiver operating characteristic curve (auroc) and the area under the precision-recall curve (auprc), and various binary classification metrics. we observe and describe a performance overestimation in the case of slice-level split as compared to the patient-level split training. the model trained using patient-level split data with the network input containing only pet slices in the cag training regime was the best performing/generalizing model on a majority of metrics. our models were additionally more closely compared using the sensitivity metric on the positive slices from their respective test sets.",2024-03-11
"150",150,"overcoming the paradox of certified training with gaussian smoothing","stefan balauca, mark niklas m√ºller, yuhao mao, maximilian baader, marc fischer, martin vechev","machine learning","training neural networks with high certified accuracy against adversarial examples remains an open problem despite significant efforts. while certification methods can effectively leverage tight convex relaxations for bound computation, in training, these methods perform worse than looser relaxations. prior work hypothesized that this is caused by the discontinuity and perturbation sensitivity of the loss surface induced by these tighter relaxations. in this work, we show theoretically that gaussian loss smoothing can alleviate both of these issues. we confirm this empirically by proposing a certified training method combining pgpe, an algorithm computing gradients of a smoothed loss, with different convex relaxations. when using this training method, we observe that tighter bounds indeed lead to strictly better networks that can outperform state-of-the-art methods on the same network. while scaling pgpe-based training remains challenging due to high computational cost, our results clearly demonstrate the promise of gaussian loss smoothing for training certifiably robust neural networks.",2024-03-11
